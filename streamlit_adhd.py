# -*- coding: utf-8 -*-

# 1. IMPORTS STREAMLIT EN PREMIER
import streamlit as st

# 2. CONFIGURATION DE LA PAGE IMM√âDIATEMENT APR√àS
st.set_page_config(
    page_title="D√©pistage TDAH",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

import streamlit as st
import uuid
import hashlib
import time
from datetime import datetime

class GDPRConsentManager:
    """Gestionnaire des consentements RGPD"""
    @staticmethod
    def show_consent_form():
        st.markdown("""
        **Protection des Donn√©es Personnelles**
        ### Vos droits :
        - ‚úÖ **Droit d'acc√®s** : Consulter vos donn√©es personnelles
        - ‚úÖ **Droit de rectification** : Corriger vos donn√©es
        - ‚úÖ **Droit √† l'effacement** : Supprimer vos donn√©es
        - ‚úÖ **Droit √† la portabilit√©** : R√©cup√©rer vos donn√©es
        - ‚úÖ **Droit d'opposition** : Refuser le traitement
        ### Traitement des donn√©es :
        - üîê **Chiffrement AES-256** de toutes les donn√©es sensibles
        - üè• **Usage m√©dical uniquement** pour le d√©pistage TDAH
        - ‚è∞ **Conservation limit√©e** : 24 mois maximum
        - üåç **Pas de transfert** hors Union Europ√©enne
        """)
        consent_options = st.columns(2)
        with consent_options[0]:
            consent_screening = st.checkbox(
                "‚úÖ J'accepte le traitement de mes donn√©es pour le d√©pistage TDAH",
                key="consent_screening"
            )
        with consent_options[1]:
            consent_research = st.radio(
                "üìä J'accepte l'utilisation anonymis√©e pour la recherche",
                options=["Non", "Oui"],
                key="consent_research_radio",
                horizontal=True
            )
        if consent_screening:
            consent_data = {
                'user_id': str(uuid.uuid4()),
                'timestamp': datetime.now().isoformat(),
                'screening_consent': True,
                'research_consent': consent_research == "Oui",
                'ip_hash': hashlib.sha256(st.session_state.get('client_ip', '').encode()).hexdigest()[:16]
            }
            st.session_state.gdpr_consent = consent_data
            st.session_state.gdpr_compliant = True
            st.success("‚úÖ Consentement enregistr√©. Redirection...")
            time.sleep(1.5)
            st.session_state.tool_choice = "üè† Accueil"
            st.rerun()
            return True
        else:
            st.warning("‚ö†Ô∏è Le consentement est requis pour utiliser l'outil de d√©pistage")
            return False

if 'gdpr_compliant' not in st.session_state or not st.session_state.gdpr_compliant:
    st.session_state.tool_choice = "üîí RGPD & Droits"
    GDPRConsentManager.show_consent_form()
    st.stop()

# 3. IMPORTS DES AUTRES BIBLIOTH√àQUES APR√àS
import os
import pickle
import hashlib
import warnings
from io import BytesIO
import hashlib
import json
from datetime import datetime
import pandas as pd

from concurrent.futures import ThreadPoolExecutor
import sys
try:
    import numpy as np
    import pandas as pd
    # Rendre numpy accessible globalement
    globals()['np'] = np
    globals()['pd'] = pd
    NUMPY_AVAILABLE = True
except ImportError as e:
    st.error(f"‚ùå Erreur critique : {e}")
    st.error("Veuillez installer numpy et pandas : pip install numpy pandas")
    st.stop()

# Imports visualisation avec gestion d'erreur am√©lior√©e
try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    import matplotlib.pyplot as plt
    import seaborn as sns
    # Rendre plotly accessible globalement
    globals()['px'] = px
    globals()['go'] = go
    globals()['make_subplots'] = make_subplots
    PLOTLY_AVAILABLE = True
except ImportError as e:
    PLOTLY_AVAILABLE = False
    st.warning(f"‚ö†Ô∏è Biblioth√®ques de visualisation non disponibles : {e}")

# Imports ML avec gestion d'erreur robuste
try:
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
    from sklearn.preprocessing import StandardScaler
    from scipy import stats
    from scipy.stats import mannwhitneyu, chi2_contingency, pearsonr, spearmanr
    SKLEARN_AVAILABLE = True
except ImportError as e:
    SKLEARN_AVAILABLE = False
    st.warning(f"‚ö†Ô∏è Scikit-learn non disponible : {e}")

# Suppression des warnings
warnings.filterwarnings('ignore')


# Cr√©ation des dossiers de cache
for folder in ['data_cache', 'image_cache', 'model_cache', 'theme_cache']:
    os.makedirs(folder, exist_ok=True)

# √âtat de session pour les scores ADHD-RS
if "adhd_total" not in st.session_state:
    st.session_state.adhd_total = 0

if "adhd_responses" not in st.session_state:
    st.session_state.adhd_responses = []

# Questions ASRS officielles
ASRS_QUESTIONS = {
    "Partie A - Questions de d√©pistage principal": [
        "√Ä quelle fr√©quence avez-vous des difficult√©s √† terminer les d√©tails finaux d'un projet, une fois que les parties difficiles ont √©t√© faites ?",
        "√Ä quelle fr√©quence avez-vous des difficult√©s √† organiser les t√¢ches lorsque vous devez faire quelque chose qui demande de l'organisation ?",
        "√Ä quelle fr√©quence avez-vous des probl√®mes pour vous rappeler des rendez-vous ou des obligations ?",
        "Quand vous avez une t√¢che qui demande beaucoup de r√©flexion, √† quelle fr√©quence √©vitez-vous ou retardez-vous de commencer ?",
        "√Ä quelle fr√©quence bougez-vous ou vous tortillez-vous avec vos mains ou vos pieds quand vous devez rester assis longtemps ?",
        "√Ä quelle fr√©quence vous sentez-vous excessivement actif et oblig√© de faire des choses, comme si vous √©tiez men√© par un moteur ?"
    ],
    "Partie B - Questions compl√©mentaires": [
        "√Ä quelle fr√©quence faites-vous des erreurs d'inattention quand vous travaillez sur un projet ennuyeux ou difficile ?",
        "√Ä quelle fr√©quence avez-vous des difficult√©s √† maintenir votre attention quand vous faites un travail ennuyeux ou r√©p√©titif ?",
        "√Ä quelle fr√©quence avez-vous des difficult√©s √† vous concentrer sur ce que les gens vous disent, m√™me quand ils s'adressent directement √† vous ?",
        "√Ä quelle fr√©quence √©garez-vous ou avez des difficult√©s √† retrouver des choses √† la maison ou au travail ?",
        "√Ä quelle fr√©quence √™tes-vous distrait par l'activit√© ou le bruit autour de vous ?",
        "√Ä quelle fr√©quence quittez-vous votre si√®ge dans des r√©unions ou d'autres situations o√π vous devriez rester assis ?",
        "√Ä quelle fr√©quence vous sentez-vous agit√© ou nerveux ?",
        "√Ä quelle fr√©quence avez-vous des difficult√©s √† vous d√©tendre quand vous avez du temps libre ?",
        "√Ä quelle fr√©quence vous retrouvez-vous √† trop parler dans des situations sociales ?",
        "Quand vous √™tes en conversation, √† quelle fr√©quence finissez-vous les phrases des personnes √† qui vous parlez, avant qu'elles puissent les finir elles-m√™mes ?",
        "√Ä quelle fr√©quence avez-vous des difficult√©s √† attendre votre tour dans des situations o√π chacun doit attendre son tour ?",
        "√Ä quelle fr√©quence interrompez-vous les autres quand ils sont occup√©s ?"
    ]
}

ASRS_OPTIONS = {
    0: "Jamais",
    1: "Rarement",
    2: "Parfois",
    3: "Souvent",
    4: "Tr√®s souvent"
}

def show_rgpd_panel():
    """Affiche le panneau RGPD & Conformit√© IA"""
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            üîí Panneau RGPD & Conformit√© IA
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            Protection des Donn√©es Personnelles
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Onglets conformit√©
    tabs = st.tabs([
        "üîê Consentement",
        "üõ°Ô∏è Transparence IA",
        "‚öñÔ∏è Droit √† l'Effacement",
        "üìä Portabilit√©",
        "üîç Audit Trail"
    ])
    with tabs[0]:
        st.subheader("üîê Consentement")
        GDPRConsentManager.show_consent_form()

        with tabs[1]:
            st.subheader("üõ°Ô∏è Transparence IA")
            st.markdown("""
            <div style="background-color: #e8f5e9; padding: 22px; border-radius: 12px; margin-bottom: 20px;">
                <h3 style="color: #2e7d32; margin-top: 0;">ü§ñ Conformit√© au R√®glement Europ√©en sur l'IA (AI Act)</h3>
                <ul style="color: #388e3c; line-height: 1.7; font-size: 1.1rem;">
                    <li><b>Type de syst√®me :</b> IA √† risque limit√© (Article 52 AI Act)</li>
                    <li><b>Finalit√© :</b> Aide au d√©pistage du TDAH adulte, non diagnostic m√©dical</li>
                    <li><b>Transparence :</b> L'utilisateur est inform√© qu'il interagit avec un syst√®me d'IA</li>
                    <li><b>Explicabilit√© :</b> Les facteurs de d√©cision du mod√®le sont list√©s ci-dessous</li>
                    <li><b>Supervision humaine :</b> Les r√©sultats doivent √™tre interpr√©t√©s par un professionnel</li>
                </ul>
                <p style="color: #388e3c; margin-top: 12px;">
                    Le mod√®le utilise les r√©ponses au questionnaire ASRS, les donn√©es d√©mographiques et des variables de qualit√© de vie pour estimer la probabilit√© de TDAH.
                </p>
            </div>
            """, unsafe_allow_html=True)

            st.markdown("""
            <div style="background-color: #fff3e0; padding: 18px; border-radius: 10px; margin-bottom: 16px;">
                <h4 style="color: #ef6c00; margin-top: 0;">üìù Facteurs pris en compte par l‚ÄôIA</h4>
                <ul style="color: #f57c00; line-height: 1.6; font-size: 1.05rem;">
                    <li>Score ASRS Partie A (questions principales)</li>
                    <li>Score ASRS Partie B (questions compl√©mentaires)</li>
                    <li>Profil symptomatique inattention/hyperactivit√©</li>
                    <li>Donn√©es d√©mographiques (√¢ge, genre, √©ducation...)</li>
                    <li>Qualit√© de vie et niveau de stress</li>
                    <li>Coh√©rence et pattern des r√©ponses</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

            col1, col2 = st.columns(2)
            with col1:
                st.markdown("""
                <div class="info-card-modern">
                    <h4 style="color: #ff5722; margin-top: 0;">üìä Performances du mod√®le</h4>
                    <ul style="color: #d84315; line-height: 1.7; font-size: 1rem;">
                        <li>Sensibilit√© : <b>87.3%</b></li>
                        <li>Sp√©cificit√© : <b>91.2%</b></li>
                        <li>AUC-ROC : <b>0.91</b></li>
                        <li>Exactitude globale : <b>89.8%</b></li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
            with col2:
                st.markdown("""
                <div class="info-card-modern">
                    <h4 style="color: #388e3c; margin-top: 0;">‚ö†Ô∏è Limites et pr√©cautions</h4>
                    <ul style="color: #388e3c; line-height: 1.7; font-size: 1rem;">
                        <li>Ce r√©sultat n'est pas un diagnostic m√©dical</li>
                        <li>Validation sur population fran√ßaise/europ√©enne</li>
                        <li>Peut g√©n√©rer des faux positifs/n√©gatifs</li>
                        <li>Supervision professionnelle indispensable</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            st.info("Pour toute question sur l'IA ou vos droits num√©riques, contactez le DPO")

        with tabs[2]:
            st.subheader("‚öñÔ∏è Exercice du Droit √† l'Effacement")

            st.markdown("""
            <div style="background-color: #ffebee; padding: 20px; border-radius: 10px; margin-bottom: 20px; border-left: 4px solid #f44336;">
                <h3 style="color: #c62828;">üóëÔ∏è Suppression de vos Donn√©es</h3>
                <p style="color: #d32f2f; line-height: 1.6;">
                    Vous pouvez demander la suppression de toutes vos donn√©es personnelles.
                    Cette action est <strong>irr√©versible</strong>.
                </p>
            </div>
            """, unsafe_allow_html=True)

            with st.form("data_deletion_form"):
                st.warning("‚ö†Ô∏è La suppression effacera d√©finitivement :")
                st.write("‚Ä¢ Vos r√©ponses au test ASRS")
                st.write("‚Ä¢ Vos donn√©es d√©mographiques")
                st.write("‚Ä¢ Vos r√©sultats d'analyse IA")
                st.write("‚Ä¢ Votre historique de consentements")

                deletion_reason = st.selectbox(
                    "Motif de suppression (optionnel)",
                    ["Non sp√©cifi√©", "Retrait du consentement", "Donn√©es incorrectes",
                     "Finalit√© atteinte", "Opposition au traitement"]
                )

                confirm_deletion = st.checkbox(
                    "Je confirme vouloir supprimer d√©finitivement mes donn√©es"
                )

                submitted = st.form_submit_button("üóëÔ∏è Supprimer mes donn√©es", type="secondary")

                if submitted and confirm_deletion:
                    # Suppression des donn√©es de session
                    keys_to_delete = ['asrs_responses', 'asrs_results', 'rgpd_consent', 'user_data']
                    for key in keys_to_delete:
                        if key in st.session_state:
                            del st.session_state[key]

                    st.success("‚úÖ Vos donn√©es ont √©t√© supprim√©es avec succ√®s")
                    st.balloons()
                elif submitted:
                    st.error("‚ùå Veuillez confirmer la suppression")
        with tabs[3]:
            st.subheader("üìä Portabilit√© de vos Donn√©es")

            if 'asrs_results' in st.session_state and 'rgpd_consent' in st.session_state:
                st.info("T√©l√©chargez vos donn√©es dans un format lisible par machine")

                # Pr√©paration des donn√©es pour export
                export_data = {
                    'donn√©es_personnelles': {
                        'age': st.session_state.asrs_results['demographics']['age'],
                        'genre': st.session_state.asrs_results['demographics']['gender'],
                        'education': st.session_state.asrs_results['demographics']['education']
                    },
                    'r√©ponses_asrs': st.session_state.asrs_results['responses'],
                    'scores_calcul√©s': st.session_state.asrs_results['scores'],
                    'consentements': st.session_state.rgpd_consent,
                    'export_timestamp': datetime.now().isoformat()
                }

                # Boutons de t√©l√©chargement
                col1, col2 = st.columns(2)

                with col1:
                    json_data = json.dumps(export_data, indent=2, ensure_ascii=False)
                    st.download_button(
                        "üì• T√©l√©charger en JSON",
                        json_data,
                        f"mes_donnees_tdah_{datetime.now().strftime('%Y%m%d')}.json",
                        "application/json"
                    )

                with col2:
                    csv_data = pd.DataFrame([export_data['donn√©es_personnelles']]).to_csv(index=False)
                    st.download_button(
                        "üì• T√©l√©charger en CSV",
                        csv_data,
                        f"mes_donnees_tdah_{datetime.now().strftime('%Y%m%d')}.csv",
                        "text/csv"
                    )
            else:
                st.warning("Aucune donn√©e disponible pour l'export")
        with tabs[4]:
            st.subheader("üîç Journal d'Audit")

            # Cr√©ation d'un log d'audit
            if 'audit_log' not in st.session_state:
                st.session_state.audit_log = []

            # Fonction de logging
            def log_action(action, details=""):
                timestamp = datetime.now().isoformat()
                st.session_state.audit_log.append({
                    'timestamp': timestamp,
                    'action': action,
                    'details': details,
                    'user_hash': hashlib.sha256(st.session_state.get('user_ip', '').encode()).hexdigest()[:8]
                })

            # Affichage du journal
            if st.session_state.audit_log:
                st.markdown("### üìã Historique de vos actions")

                audit_df = pd.DataFrame(st.session_state.audit_log)
                audit_df['timestamp'] = pd.to_datetime(audit_df['timestamp']).dt.strftime('%d/%m/%Y %H:%M')

                st.dataframe(
                    audit_df[['timestamp', 'action', 'details']],
                    use_container_width=True,
                    hide_index=True
                )

                # Export de l'audit
                audit_csv = audit_df.to_csv(index=False)
                st.download_button(
                    "üì• T√©l√©charger l'audit",
                    audit_csv,
                    f"audit_tdah_{datetime.now().strftime('%Y%m%d')}.csv",
                    "text/csv"
                )
            else:
                st.info("Aucune action enregistr√©e pour cette session")


def check_rgpd_consent():
    """V√©rifie si le consentement RGPD est donn√©"""
    if 'rgpd_consent' not in st.session_state:
        st.warning("‚ö†Ô∏è Veuillez donner votre consentement RGPD avant de continuer")
        if st.button("üîí Aller au panneau RGPD"):
            st.session_state.tool_choice = "üîí Panneau RGPD & Conformit√© IA"
            st.rerun()
        return False

    consent = st.session_state.rgpd_consent
    return consent.get('data_processing', False) and consent.get('ai_analysis', False)

# Utilisation dans les fonctions de test
def show_enhanced_ai_prediction():
    """Interface de pr√©diction IA enrichie avec test ASRS complet"""
    # V√©rification du consentement en premier
    if not check_rgpd_consent():
        return

def check_dependencies():
    """V√©rifie la disponibilit√© des d√©pendances critiques"""
    missing_deps = []

    # V√©rification numpy/pandas
    try:
        import numpy as np
        import pandas as pd
    except ImportError:
        missing_deps.append("numpy/pandas")

    # V√©rification plotly
    try:
        import plotly.express as px
        import plotly.graph_objects as go
    except ImportError:
        missing_deps.append("plotly")

    if missing_deps:
        st.error(f"‚ùå D√©pendances manquantes : {', '.join(missing_deps)}")
        st.code("pip install numpy pandas plotly streamlit scikit-learn", language="bash")
        st.stop()

    return True

# Appel de la v√©rification au d√©but de l'application
check_dependencies()

def safe_calculation(func, fallback_value=0, error_message="Erreur de calcul"):
    """Wrapper pour les calculs avec gestion d'erreur"""
    try:
        return func()
    except Exception as e:
        st.warning(f"‚ö†Ô∏è {error_message} : {str(e)}")
        return fallback_value

def initialize_session_state():
    """Initialise l'√©tat de session pour conserver les configurations entre les recharges"""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        default_tool = "üè† Accueil"

        try:
            if "selection" in st.query_params:
                selection = st.query_params["selection"]
                selection_mapping = {
                    "üìù Test ADHD-RS": "ü§ñ Pr√©diction par IA",
                    "ü§ñ Pr√©diction par IA": "ü§ñ Pr√©diction par IA",
                    "üîç Exploration des Donn√©es": "üîç Exploration des Donn√©es"
                }
                if selection in selection_mapping:
                    st.session_state.tool_choice = selection_mapping[selection]
                else:
                    st.session_state.tool_choice = default_tool
            else:
                st.session_state.tool_choice = default_tool
        except:
            st.session_state.tool_choice = default_tool

        st.session_state.data_exploration_expanded = True

def set_custom_theme():
    """D√©finit le th√®me personnalis√© avec palette orange pour le TDAH"""
    css_path = "theme_cache/custom_theme_tdah.css"
    os.makedirs(os.path.dirname(css_path), exist_ok=True)

    if os.path.exists(css_path):
        with open(css_path, 'r') as f:
            custom_theme = f.read()
    else:
        # CSS corrig√© avec cha√Ænes de caract√®res correctement ferm√©es
        custom_theme = """
        <style>
        :root {
            --primary: #d84315 !important;
            --secondary: #ff5722 !important;
            --accent: #ff9800 !important;
            --background: #fff8f5 !important;
            --sidebar-bg: #ffffff !important;
            --sidebar-border: #ffccbc !important;
            --text-primary: #d84315 !important;
            --text-secondary: #bf360c !important;
            --sidebar-width-collapsed: 60px !important;
            --sidebar-width-expanded: 240px !important;
            --sidebar-transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
            --shadow-light: 0 2px 8px rgba(255,87,34,0.08) !important;
            --shadow-medium: 0 4px 16px rgba(255,87,34,0.12) !important;
        }

        [data-testid="stAppViewContainer"] {
            background-color: var(--background) !important;
        }

        [data-testid="stSidebar"] {
            width: var(--sidebar-width-collapsed) !important;
            min-width: var(--sidebar-width-collapsed) !important;
            max-width: var(--sidebar-width-collapsed) !important;
            height: 100vh !important;
            position: fixed !important;
            left: 0 !important;
            top: 0 !important;
            z-index: 999999 !important;
            background: var(--sidebar-bg) !important;
            border-right: 1px solid var(--sidebar-border) !important;
            box-shadow: var(--shadow-light) !important;
            overflow: hidden !important;
            padding: 0 !important;
            transition: var(--sidebar-transition) !important;
        }

        [data-testid="stSidebar"]:hover {
            width: var(--sidebar-width-expanded) !important;
            min-width: var(--sidebar-width-expanded) !important;
            max-width: var(--sidebar-width-expanded) !important;
            box-shadow: var(--shadow-medium) !important;
            overflow-y: auto !important;
        }

        [data-testid="stSidebar"] > div {
            width: var(--sidebar-width-expanded) !important;
            padding: 12px 8px !important;
            height: 100vh !important;
            overflow: hidden !important;
        }

        [data-testid="stSidebar"]:hover > div {
            overflow-y: auto !important;
            padding: 16px 12px !important;
        }

        [data-testid="stSidebar"] h2 {
            font-size: 0 !important;
            margin: 0 0 20px 0 !important;
            padding: 12px 0 !important;
            border-bottom: 1px solid var(--sidebar-border) !important;
            text-align: center !important;
            transition: all 0.3s ease !important;
            position: relative !important;
            height: 60px !important;
            display: flex !important;
            align-items: center !important;
            justify-content: center !important;
        }

        [data-testid="stSidebar"] h2::before {
            content: "üß†" !important;
            font-size: 28px !important;
            display: block !important;
            margin: 0 !important;
        }

        [data-testid="stSidebar"]:hover h2 {
            font-size: 1.4rem !important;
            color: var(--primary) !important;
            font-weight: 600 !important;
        }

        [data-testid="stSidebar"]:hover h2::before {
            font-size: 20px !important;
            margin-right: 8px !important;
        }

        [data-testid="stSidebar"] .stRadio {
            padding: 0 !important;
            margin: 0 !important;
        }

        [data-testid="stSidebar"] .stRadio > div {
            display: flex !important;
            flex-direction: column !important;
            gap: 4px !important;
            padding: 0 !important;
        }

        [data-testid="stSidebar"] .stRadio label {
            display: flex !important;
            align-items: center !important;
            padding: 10px 6px !important;
            margin: 0 !important;
            border-radius: 8px !important;
            transition: all 0.3s ease !important;
            cursor: pointer !important;
            position: relative !important;
            height: 44px !important;
            overflow: hidden !important;
            background: transparent !important;
        }

        [data-testid="stSidebar"] .stRadio label > div:first-child {
            display: none !important;
        }

        [data-testid="stSidebar"] .stRadio label span {
            font-size: 0 !important;
            transition: all 0.3s ease !important;
            width: 100% !important;
            text-align: center !important;
            position: relative !important;
        }

        [data-testid="stSidebar"] .stRadio label span::before {
            font-size: 22px !important;
            display: block !important;
            width: 100% !important;
            text-align: center !important;
        }

        [data-testid="stSidebar"] .stRadio label:nth-child(1) span::before { content: "üè†" !important; }
        [data-testid="stSidebar"] .stRadio label:nth-child(2) span::before { content: "üîç" !important; }
        [data-testid="stSidebar"] .stRadio label:nth-child(3) span::before { content: "üß†" !important; }
        [data-testid="stSidebar"] .stRadio label:nth-child(4) span::before { content: "ü§ñ" !important; }
        [data-testid="stSidebar"] .stRadio label:nth-child(5) span::before { content: "üìö" !important; }
        [data-testid="stSidebar"] .stRadio label:nth-child(6) span::before { content: "‚ÑπÔ∏è" !important; }

        [data-testid="stSidebar"]:hover .stRadio label span {
            font-size: 14px !important;
            font-weight: 500 !important;
            text-align: left !important;
            padding-left: 12px !important;
        }

        [data-testid="stSidebar"]:hover .stRadio label span::before {
            font-size: 18px !important;
            position: absolute !important;
            left: -8px !important;
            top: 50% !important;
            transform: translateY(-50%) !important;
            width: auto !important;
        }

        [data-testid="stSidebar"] .stRadio label:hover {
            background: linear-gradient(135deg, #fff3e0, #ffe0b2) !important;
            transform: translateX(3px) !important;
            box-shadow: var(--shadow-light) !important;
        }

        [data-testid="stSidebar"] .stRadio label[data-checked="true"] {
            background: linear-gradient(135deg, var(--secondary), var(--accent)) !important;
            color: white !important;
            box-shadow: var(--shadow-medium) !important;
        }

        [data-testid="stSidebar"] .stRadio label[data-checked="true"]:hover {
            background: linear-gradient(135deg, var(--accent), var(--secondary)) !important;
            transform: translateX(5px) !important;
        }

        .main .block-container {
            margin-left: calc(var(--sidebar-width-collapsed) + 16px) !important;
            padding: 1.5rem !important;
            max-width: calc(100vw - var(--sidebar-width-collapsed) - 32px) !important;
            transition: var(--sidebar-transition) !important;
        }

        .stButton > button {
            background: linear-gradient(135deg, var(--secondary), var(--accent)) !important;
            color: white !important;
            border-radius: 8px !important;
            border: none !important;
            padding: 10px 20px !important;
            font-weight: 500 !important;
            transition: all 0.3s ease !important;
            box-shadow: var(--shadow-light) !important;
        }

        .stButton > button:hover {
            transform: translateY(-2px) !important;
            box-shadow: var(--shadow-medium) !important;
            background: linear-gradient(135deg, var(--accent), var(--secondary)) !important;
        }

        .info-card-modern {
            background: white;
            border-radius: 15px;
            padding: 25px;
            margin: 15px 0;
            box-shadow: 0 4px 15px rgba(255,87,34,0.08);
            border-left: 4px solid var(--secondary);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .info-card-modern:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(255,87,34,0.15);
        }

        .stAlert, [data-testid="stAlert"] {
            border: none !important;
            background: transparent !important;
        }

        .asrs-question-card {
            background: linear-gradient(135deg, #fff3e0, #ffcc02);
            border-radius: 12px;
            padding: 20px;
            margin: 15px 0;
            border-left: 4px solid #ff5722;
            box-shadow: 0 3px 10px rgba(255,87,34,0.1);
        }

        .info-card-modern {
            background: white;
            border-radius: 15px;
            padding: 25px;
            margin: 15px 0;
            box-shadow: 0 4px 15px rgba(255,87,34,0.08);
            border-left: 4px solid #ff5722;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .info-card-modern:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 25px rgba(255,87,34,0.15);
        }

        .asrs-option-container {
            display: flex;
            justify-content: space-between;
            margin-top: 15px;
            flex-wrap: wrap;
            gap: 10px;
        }

        .asrs-option {
            flex: 1;
            min-width: 80px;
            text-align: center;
        }
        </style>

        <script>
        document.addEventListener('DOMContentLoaded', function() {
            const sidebar = document.querySelector('[data-testid="stSidebar"]');

            if (sidebar) {
                let isExpanded = false;
                let hoverTimeout;

                function expandSidebar() {
                    clearTimeout(hoverTimeout);
                    isExpanded = true;
                    sidebar.style.overflow = 'visible';
                }

                function collapseSidebar() {
                    hoverTimeout = setTimeout(() => {
                        isExpanded = false;
                        sidebar.style.overflow = 'hidden';
                    }, 200);
                }

                sidebar.addEventListener('mouseenter', expandSidebar);
                sidebar.addEventListener('mouseleave', collapseSidebar);

                const observer = new MutationObserver(() => {
                    const radioLabels = sidebar.querySelectorAll('.stRadio label');
                    radioLabels.forEach(label => {
                        const input = label.querySelector('input[type="radio"]');
                        if (input && input.checked) {
                            label.setAttribute('data-checked', 'true');
                        } else {
                            label.setAttribute('data-checked', 'false');
                        }
                    });
                });

                observer.observe(sidebar, {
                    childList: true,
                    subtree: true,
                    attributes: true
                });
            }
        });
        </script>
        """

        with open(css_path, 'w') as f:
            f.write(custom_theme)

    st.markdown(custom_theme, unsafe_allow_html=True)

def show_navigation_menu():
    """Menu de navigation optimis√© pour le TDAH"""
    st.markdown("## üß† TDAH - Navigation")
    st.markdown("Choisissez un outil :")

    options = [
        "üè† Accueil",
        "üîç Exploration",
        "üß† Analyse ML",
        "ü§ñ Pr√©diction par IA",
        "üìö Documentation",
        "üîí Panneau RGPD & Conformit√© IA",
        "‚ÑπÔ∏è √Ä propos"
    ]

    if 'tool_choice' not in st.session_state or st.session_state.tool_choice not in options:
        st.session_state.tool_choice = "üè† Accueil"

    current_index = options.index(st.session_state.tool_choice)

    tool_choice = st.radio(
        "",
        options,
        label_visibility="collapsed",
        index=current_index,
        key="main_navigation"
    )

    if tool_choice != st.session_state.tool_choice:
        st.session_state.tool_choice = tool_choice

    return tool_choice


def safe_numpy_operation(operation, data, fallback_value=0):
    """
    Ex√©cute une op√©ration numpy de mani√®re s√©curis√©e avec fallback
    """
    try:
        import numpy as np_safe
        return operation(np_safe, data)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Op√©ration numpy √©chou√©e : {e}. Utilisation de calcul alternatif.")
        return fallback_value

def calculate_std_safe(values):
    """
    Calcul d'√©cart-type s√©curis√© avec ou sans numpy
    """
    try:
        import numpy as np_std
        return np_std.std(values)
    except:
        # Calcul manuel de l'√©cart-type
        if len(values) == 0:
            return 0
        mean_val = sum(values) / len(values)
        variance = sum((x - mean_val) ** 2 for x in values) / len(values)
        return variance ** 0.5


@st.cache_data(ttl=86400)
def load_enhanced_dataset():
    """Charge le dataset TDAH enrichi depuis Google Drive avec gestion d'erreur"""
    try:
        # Import local de pandas pour √©viter les erreurs de port√©e
        import pandas as pd_local
        import numpy as np_local

        # URL du dataset Google Drive
        url = 'https://drive.google.com/file/d/1EMiEsDyetI82vrs1FL2kyxUI-WD4v3Cs/view?usp=drive_link'
        file_id = url.split('/d/')[1].split('/')[0]
        download_url = f'https://drive.google.com/uc?export=download&id={file_id}'

        # Chargement du dataset
        df = pd_local.read_csv(download_url)
        return df

    except Exception as e:
        st.error(f"Erreur lors du chargement du dataset Google Drive: {str(e)}")
        st.info("Utilisation de donn√©es simul√©es √† la place")
        return create_fallback_dataset()

def create_fallback_dataset():
    """Cr√©e un dataset de fallback avec imports locaux s√©curis√©s"""
    try:
        import numpy as np_fallback
        import pandas as pd_fallback

        np_fallback.random.seed(42)
        n_samples = 1500

        # Structure bas√©e sur le vrai dataset
        data = {
            'subject_id': [f'FALLBACK_{str(i).zfill(5)}' for i in range(1, n_samples + 1)],
            'age': np_fallback.random.randint(18, 65, n_samples),
            'gender': np_fallback.random.choice(['M', 'F'], n_samples),
            'diagnosis': np_fallback.random.binomial(1, 0.3, n_samples),
            'site': np_fallback.random.choice(['Site_Paris', 'Site_Lyon', 'Site_Marseille'], n_samples),
        }

        # Questions ASRS
        for i in range(1, 19):
            data[f'asrs_q{i}'] = np_fallback.random.randint(0, 5, n_samples)

        # Scores calcul√©s
        data['asrs_inattention'] = np_fallback.random.randint(0, 36, n_samples)
        data['asrs_hyperactivity'] = np_fallback.random.randint(0, 36, n_samples)
        data['asrs_total'] = data['asrs_inattention'] + data['asrs_hyperactivity']
        data['asrs_part_a'] = np_fallback.random.randint(0, 24, n_samples)
        data['asrs_part_b'] = np_fallback.random.randint(0, 48, n_samples)

        # Variables suppl√©mentaires
        data.update({
            'education': np_fallback.random.choice(['Bac', 'Bac+2', 'Bac+3', 'Bac+5', 'Doctorat'], n_samples),
            'job_status': np_fallback.random.choice(['CDI', 'CDD', 'Freelance', '√âtudiant', 'Ch√¥meur'], n_samples),
            'marital_status': np_fallback.random.choice(['C√©libataire', 'En couple', 'Mari√©(e)', 'Divorc√©(e)'], n_samples),
            'quality_of_life': np_fallback.random.uniform(1, 10, n_samples),
            'stress_level': np_fallback.random.uniform(1, 5, n_samples),
            'sleep_problems': np_fallback.random.uniform(1, 5, n_samples),
        })

        return pd_fallback.DataFrame(data)

    except Exception as e:
        st.error(f"Erreur critique dans la cr√©ation du dataset de fallback : {e}")
        # Retourner un DataFrame vide plut√¥t que de planter
        return pd.DataFrame()


def test_numpy_availability():
    """Test de disponibilit√© de numpy et pandas"""
    try:
        import numpy as test_np
        import pandas as test_pd

        # Test simple
        test_array = test_np.array([1, 2, 3, 4, 5])
        test_std = test_np.std(test_array)
        test_df = test_pd.DataFrame({'test': [1, 2, 3]})
        return True

    except Exception as e:
        st.error(f"‚ùå Test numpy/pandas √©chou√© : {e}")
        return False

# Appeler le test au d√©but de l'application
if 'numpy_tested' not in st.session_state:
    st.session_state.numpy_tested = test_numpy_availability()


def create_fallback_dataset():
    """Cr√©e un dataset de fallback compatible avec la structure attendue"""
    np.random.seed(42)
    n_samples = 1500

    # Structure bas√©e sur le vrai dataset
    data = {
        'subject_id': [f'FALLBACK_{str(i).zfill(5)}' for i in range(1, n_samples + 1)],
        'age': np.random.randint(18, 65, n_samples),
        'gender': np.random.choice(['M', 'F'], n_samples),
        'diagnosis': np.random.binomial(1, 0.3, n_samples),
        'site': np.random.choice(['Site_Paris', 'Site_Lyon', 'Site_Marseille'], n_samples),
    }

    # Questions ASRS
    for i in range(1, 19):
        data[f'asrs_q{i}'] = np.random.randint(0, 5, n_samples)

    # Scores calcul√©s
    data['asrs_inattention'] = np.random.randint(0, 36, n_samples)
    data['asrs_hyperactivity'] = np.random.randint(0, 36, n_samples)
    data['asrs_total'] = data['asrs_inattention'] + data['asrs_hyperactivity']
    data['asrs_part_a'] = np.random.randint(0, 24, n_samples)
    data['asrs_part_b'] = np.random.randint(0, 48, n_samples)

    # Variables suppl√©mentaires
    data.update({
        'education': np.random.choice(['Bac', 'Bac+2', 'Bac+3', 'Bac+5', 'Doctorat'], n_samples),
        'job_status': np.random.choice(['CDI', 'CDD', 'Freelance', '√âtudiant', 'Ch√¥meur'], n_samples),
        'marital_status': np.random.choice(['C√©libataire', 'En couple', 'Mari√©(e)', 'Divorc√©(e)'], n_samples),
        'quality_of_life': np.random.uniform(1, 10, n_samples),
        'stress_level': np.random.uniform(1, 5, n_samples),
        'sleep_problems': np.random.uniform(1, 5, n_samples),
    })

    return pd.DataFrame(data)

def perform_statistical_tests(df):
    """Effectue des tests statistiques avanc√©s sur le dataset"""
    results = {}

    # Test de Mann-Whitney pour les variables num√©riques
    numeric_vars = ['age', 'asrs_total', 'asrs_inattention', 'asrs_hyperactivity', 'quality_of_life', 'stress_level']

    for var in numeric_vars:
        if var in df.columns:
            group_0 = df[df['diagnosis'] == 0][var].dropna()
            group_1 = df[df['diagnosis'] == 1][var].dropna()

            if len(group_0) > 0 and len(group_1) > 0:
                statistic, p_value = mannwhitneyu(group_0, group_1, alternative='two-sided')
                results[f'mannwhitney_{var}'] = {
                    'statistic': statistic,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'group_0_median': np.median(group_0),
                    'group_1_median': np.median(group_1)
                }

    # Test du Chi-2 pour les variables cat√©gorielles
    categorical_vars = ['gender', 'education', 'job_status', 'marital_status']

    for var in categorical_vars:
        if var in df.columns:
            contingency_table = pd.crosstab(df[var], df['diagnosis'])
            if contingency_table.size > 0:
                chi2, p_value, dof, expected = chi2_contingency(contingency_table)
                results[f'chi2_{var}'] = {
                    'chi2': chi2,
                    'p_value': p_value,
                    'significant': p_value < 0.05,
                    'dof': dof,
                    'contingency_table': contingency_table
                }

    return results

def show_home_page():
    """Page d'accueil pour le TDAH avec design moderne"""

    # CSS sp√©cifique pour la page d'accueil
    st.markdown("""
    <style>
    .info-card-modern {
        background: white;
        border-radius: 15px;
        padding: 25px;
        margin: 15px 0;
        box-shadow: 0 4px 15px rgba(255,87,34,0.08);
        border-left: 4px solid #ff5722;
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }

    .info-card-modern:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(255,87,34,0.15);
    }

    .timeline-container {
        background-color: #fff3e0;
        padding: 25px;
        border-radius: 15px;
        margin: 25px 0;
        overflow-x: auto;
    }

    .timeline-item {
        min-width: 160px;
        text-align: center;
        margin: 0 15px;
        flex-shrink: 0;
    }

    .timeline-year {
        background: linear-gradient(135deg, #ff5722, #ff9800);
        color: white;
        padding: 12px;
        border-radius: 8px;
        font-weight: bold;
        font-size: 0.95rem;
    }

    .timeline-text {
        margin-top: 12px;
        font-size: 0.9rem;
        color: #d84315;
        line-height: 1.4;
    }
    </style>
    """, unsafe_allow_html=True)

@st.cache_data(ttl=3600, show_spinner=False)
def get_optimized_css():
    """CSS optimis√© et minifi√©"""
    return """
    <style>
    .stApp { background-color: #fff8f5 !important; }
    .stButton > button {
        background: linear-gradient(135deg, #ff5722, #ff9800) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        transition: all 0.3s ease !important;
    }
    .stButton > button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(255,87,34,0.3) !important;
    }
    </style>
    """

# Appliquer le CSS optimis√© au d√©but de chaque page
if 'css_loaded' not in st.session_state:
    st.markdown(get_optimized_css(), unsafe_allow_html=True)
    st.session_state.css_loaded = True


    # En-t√™te principal
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            üß† Plateforme Avanc√©e de D√©pistage TDAH
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            Analyse de 13 886 participants avec l'√©chelle ASRS compl√®te et intelligence artificielle
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Section "Qu'est-ce que le TDAH ?"
    st.markdown("""
    <div class="info-card-modern">
        <h2 style="color: #ff5722; margin-bottom: 25px; font-size: 2.2rem; text-align: center;">
            üî¨ Qu'est-ce que le TDAH ?
        </h2>
        <p style="font-size: 1.2rem; line-height: 1.8; text-align: justify;
                  max-width: 900px; margin: 0 auto; color: #d84315;">
            Le <strong>Trouble D√©ficitaire de l'Attention avec ou sans Hyperactivit√© (TDAH)</strong> est un trouble
            neurod√©veloppemental qui se caract√©rise par des difficult√©s persistantes d'attention, d'hyperactivit√©
            et d'impulsivit√©. Ces sympt√¥mes apparaissent avant l'√¢ge de 12 ans et interf√®rent significativement
            avec le fonctionnement quotidien dans plusieurs domaines de la vie.
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Nouvelles statistiques du dataset
    df = load_enhanced_dataset()

    if df is not None and len(df) > 1000:
        # Statistiques r√©elles du dataset
        total_participants = len(df)
        tdah_cases = df['diagnosis'].sum() if 'diagnosis' in df.columns else 0
        mean_age = df['age'].mean() if 'age' in df.columns else 0
        male_ratio = (df['gender'] == 'M').mean() if 'gender' in df.columns else 0

        st.markdown("""
        <h2 style="color: #ff5722; margin: 45px 0 25px 0; text-align: center; font-size: 2.2rem;">
            üìä Donn√©es de notre √©tude
        </h2>
        """, unsafe_allow_html=True)

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "Participants total",
                f"{total_participants:,}",
                help="Nombre total de participants dans notre dataset"
            )
        with col2:
            st.metric(
                "Cas TDAH d√©tect√©s",
                f"{tdah_cases:,} ({tdah_cases/total_participants:.1%})",
                help="Proportion de participants avec diagnostic TDAH positif"
            )
        with col3:
            st.metric(
                "√Çge moyen",
                f"{mean_age:.1f} ans",
                help="√Çge moyen des participants"
            )
        with col4:
            st.metric(
                "Ratio Hommes/Femmes",
                f"{male_ratio:.1%} / {1-male_ratio:.1%}",
                help="R√©partition par genre"
            )

    # Timeline de l'√©volution
    st.markdown("""
    <h2 style="color: #ff5722; margin: 45px 0 25px 0; text-align: center; font-size: 2.2rem;">
        üìÖ √âvolution de la compr√©hension du TDAH
    </h2>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="timeline-container">
        <div style="display: flex; justify-content: space-between; min-width: 700px;">
            <div class="timeline-item">
                <div class="timeline-year">1902</div>
                <div class="timeline-text">Still d√©crit l'hyperactivit√© chez l'enfant</div>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">1980</div>
                <div class="timeline-text">Le TDAH entre dans le DSM-III</div>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">1994</div>
                <div class="timeline-text">D√©finition des 3 sous-types</div>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2023</div>
                <div class="timeline-text">√âchelle ASRS standardis√©e</div>
            </div>
            <div class="timeline-item">
                <div class="timeline-year">2025</div>
                <div class="timeline-text">IA pour le d√©pistage</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Section "Les trois dimensions du TDAH"
    st.markdown("## üåà Les trois dimensions du TDAH")

    st.markdown("""
    <div style="background-color: white; padding: 25px; border-radius: 15px;
               box-shadow: 0 4px 15px rgba(255,87,34,0.08); border-left: 4px solid #ff5722;">
        <p style="font-size: 1.1rem; line-height: 1.7; color: #d84315; margin-bottom: 20px;">
            Le TDAH se manifeste selon <strong>trois dimensions principales</strong> qui peuvent se pr√©senter
            s√©par√©ment ou en combinaison.
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Les trois types
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #ffebee, #ffcdd2);
                   border-radius: 15px; padding: 25px; margin-bottom: 20px; height: 200px;
                   border-left: 4px solid #f44336;">
            <h4 style="color: #c62828; margin-top: 0;">üéØ Inattention</h4>
            <ul style="color: #d32f2f; line-height: 1.6; font-size: 0.9rem;">
                <li>Difficult√©s de concentration</li>
                <li>Oublis fr√©quents</li>
                <li>D√©sorganisation</li>
                <li>√âvitement des t√¢ches</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #fff3e0, #ffcc02);
                   border-radius: 15px; padding: 25px; margin-bottom: 20px; height: 200px;
                   border-left: 4px solid #ff9800;">
            <h4 style="color: #ef6c00; margin-top: 0;">‚ö° Hyperactivit√©</h4>
            <ul style="color: #f57c00; line-height: 1.6; font-size: 0.9rem;">
                <li>Agitation constante</li>
                <li>Difficult√© √† rester assis</li>
                <li>√ânergie excessive</li>
                <li>Verbosit√©</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
        <div style="background: linear-gradient(135deg, #e8f5e8, #c8e6c9);
                   border-radius: 15px; padding: 25px; margin-bottom: 20px; height: 200px;
                   border-left: 4px solid #4caf50;">
            <h4 style="color: #2e7d32; margin-top: 0;">üöÄ Impulsivit√©</h4>
            <ul style="color: #388e3c; line-height: 1.6; font-size: 0.9rem;">
                <li>R√©ponses pr√©cipit√©es</li>
                <li>Interruptions fr√©quentes</li>
                <li>Impatience</li>
                <li>Prises de risques</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # Avertissement final
    st.markdown("""
    <div style="margin: 40px 0 30px 0; padding: 20px; border-radius: 12px;
               border-left: 4px solid #f44336; background: linear-gradient(135deg, #ffebee, #ffcdd2);
               box-shadow: 0 4px 12px rgba(244, 67, 54, 0.1);">
        <p style="font-size: 1rem; color: #c62828; text-align: center; margin: 0; line-height: 1.6;">
            <strong style="color: #f44336;">‚ö†Ô∏è Avertissement :</strong>
            Cette plateforme utilise des donn√©es de recherche √† des fins d'information et d'aide au d√©pistage.
            Seul un professionnel de sant√© qualifi√© peut poser un diagnostic de TDAH.
        </p>
    </div>
    """, unsafe_allow_html=True)

def determine_chart_type(x_is_numeric, y_is_numeric, y_var, force_chart_type=None):
    """D√©termine automatiquement le type de graphique appropri√©"""

    if force_chart_type:
        return force_chart_type

    # Logique automatique
    if not y_var:
        return "histogram" if x_is_numeric else "bar"
    else:
        if x_is_numeric and y_is_numeric:
            return "scatter"
        elif x_is_numeric and not y_is_numeric:
            return "box"
        elif not x_is_numeric and y_is_numeric:
            return "violin"
        else:
            return "heatmap"

def create_chart_by_type(df, x_var, y_var, color_var, chart_type, selected_colors, x_is_numeric, y_is_numeric):
    """Cr√©e le graphique selon le type sp√©cifi√© - VERSION CORRIG√âE"""

    try:
        if chart_type == "histogram":
            fig = px.histogram(
                df,
                x=x_var,
                color=color_var,
                nbins=min(30, df[x_var].nunique()) if x_is_numeric else None,
                color_discrete_sequence=selected_colors,
                title=f'Distribution de {x_var}'
            )

        elif chart_type == "bar":
            if x_is_numeric:
                df_temp = df.copy()
                df_temp[f'{x_var}_bins'] = pd.cut(df_temp[x_var], bins=10)
                chart_data = df_temp[f'{x_var}_bins'].value_counts().reset_index()
                chart_data.columns = ['categories', 'count']
            else:
                chart_data = df[x_var].value_counts().reset_index()
                chart_data.columns = ['categories', 'count']

            fig = px.bar(
                chart_data,
                x='categories',
                y='count',
                color='categories',
                color_discrete_sequence=selected_colors,
                title=f'Distribution de {x_var}'
            )

        elif chart_type == "scatter":
            fig = px.scatter(
                df,
                x=x_var,
                y=y_var,
                color=color_var,
                trendline="lowess" if len(df) > 10 else None,
                opacity=0.7,
                color_discrete_sequence=selected_colors,
                title=f'Relation entre {x_var} et {y_var}'
            )

        elif chart_type == "box":
            fig = px.box(
                df,
                x=y_var,
                y=x_var,
                color=color_var,
                color_discrete_sequence=selected_colors,
                title=f'Distribution de {x_var} par {y_var}'
            )

        elif chart_type == "violin":
            fig = px.violin(
                df,
                x=y_var,
                y=x_var,
                color=color_var,
                box=True,
                color_discrete_sequence=selected_colors,
                title=f'Distribution de {x_var} par {y_var}'
            )

        elif chart_type == "heatmap":
            try:
                crosstab = pd.crosstab(df[x_var], df[y_var])
                fig = px.imshow(
                    crosstab,
                    color_continuous_scale='Oranges',
                    labels=dict(x=y_var, y=x_var, color="Fr√©quence"),
                    title=f'Heatmap : {x_var} vs {y_var}'
                )
            except Exception:
                # Fallback vers un graphique en barres
                chart_data = df.groupby([x_var, y_var]).size().reset_index(name='count')
                fig = px.bar(
                    chart_data,
                    x=x_var,
                    y='count',
                    color=y_var,
                    color_discrete_sequence=selected_colors,
                    title=f'Relation entre {x_var} et {y_var}'
                )

        else:
            # CORRECTION PRINCIPALE : Graphique par d√©faut pour les cas non g√©r√©s
            st.warning(f"Type de graphique '{chart_type}' non reconnu. Affichage d'un histogramme par d√©faut.")
            fig = px.histogram(
                df,
                x=x_var,
                color_discrete_sequence=selected_colors,
                title=f'Distribution de {x_var} (par d√©faut)'
            )

        # V√âRIFICATION CRITIQUE : S'assurer qu'une figure est toujours retourn√©e
        if fig is None:
            # Cr√©ation d'une figure vide en cas d'√©chec
            fig = go.Figure()
            fig.add_annotation(
                text="Erreur lors de la cr√©ation du graphique",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )

        return fig

    except Exception as e:
        # Gestion d'erreur robuste avec figure de fallback
        st.error(f"Erreur lors de la cr√©ation du graphique : {str(e)}")

        # Retour d'une figure d'erreur plut√¥t que None
        error_fig = go.Figure()
        error_fig.add_annotation(
            text=f"Erreur : {str(e)}",
            xref="paper", yref="paper",
            x=0.5, y=0.5, showarrow=False,
            font=dict(size=16, color="red")
        )
        return error_fig

def customize_chart_layout(fig, x_var, y_var, add_borders, show_values, chart_type):
    """Personnalise la mise en page du graphique"""

    # Personnalisation des traces
    fig.update_traces(
        marker=dict(
            line=dict(
                color='white' if add_borders else 'rgba(0,0,0,0)',
                width=2 if add_borders else 0
            ),
            opacity=0.85
        ),
        textposition='outside' if show_values and chart_type in ['bar', 'histogram'] else 'none',
        textfont=dict(size=11, color='black', family='Arial')
    )

    # Layout g√©n√©ral
    fig.update_layout(
        template="plotly_white",
        plot_bgcolor='white',
        paper_bgcolor='white',
        font=dict(color='black', size=11, family='Arial'),
        showlegend=True if y_var or chart_type in ['scatter', 'box', 'violin'] else False,
        title=dict(
            font=dict(size=16, color='#2E4057', family='Arial Bold'),
            x=0.5,
            pad=dict(t=20)
        ),
        margin=dict(l=50, r=50, t=70, b=50),
        height=450,
        hovermode="closest" if chart_type == "scatter" else "x unified"
    )

    fig.update_xaxes(
        title=dict(
            text=x_var,
            font=dict(size=13, family='Arial Bold', color='#2E4057')
        ),
        tickfont=dict(size=11, color='black'),
        gridcolor='lightgray',
        gridwidth=0.5
    )

    if y_var:
        fig.update_yaxes(
            title=dict(
                text=y_var,
                font=dict(size=13, family='Arial Bold', color='#2E4057')
            ),
            tickfont=dict(size=11, color='black'),
            gridcolor='lightgray',
            gridwidth=0.5
        )

def smart_visualization(df, x_var, y_var=None, color_var=None, force_chart_type=None):
    """Visualisation automatique avec exclusion compl√®te des variables techniques"""

    # Variables √† exclure syst√©matiquement des graphiques
    excluded_vars = ['source_file', 'generation_date', 'version', 'streamlit_ready', 'subject_id']

    # Filtrer le DataFrame pour la visualisation AVANT toute op√©ration
    df_viz = df.loc[:, ~df.columns.isin(excluded_vars)]

    # V√©rification que les variables s√©lectionn√©es ne sont pas dans la liste d'exclusion
    if x_var in excluded_vars:
        st.error(f"‚ùå Variable '{x_var}' est exclue des visualisations")
        st.info("üí° Cette variable technique ne peut pas √™tre utilis√©e pour les graphiques")
        return

    if y_var and y_var in excluded_vars:
        st.error(f"‚ùå Variable '{y_var}' est exclue des visualisations")
        st.info("üí° Cette variable technique ne peut pas √™tre utilis√©e pour les graphiques")
        return

    if color_var and color_var in excluded_vars:
        st.error(f"‚ùå Variable '{color_var}' est exclue des visualisations")
        st.info("üí° Cette variable technique ne peut pas √™tre utilis√©e pour les graphiques")
        return

    # Validations pr√©alables sur le DataFrame filtr√©
    if df_viz is None or df_viz.empty:
        st.error("Dataset vide ou non disponible apr√®s filtrage")
        return
    if x_var not in df_viz.columns:
        st.error(f"Variable '{x_var}' non trouv√©e dans le dataset filtr√©")
        return
    if y_var and y_var not in df_viz.columns:
        st.error(f"Variable '{y_var}' non trouv√©e dans le dataset filtr√©")
        return
    if color_var and color_var not in df_viz.columns:
        st.error(f"Variable '{color_var}' non trouv√©e dans le dataset filtr√©")
        return

    # D√©tection automatique des types de donn√©es sur le DataFrame filtr√©
    x_is_numeric = pd.api.types.is_numeric_dtype(df_viz[x_var])
    y_is_numeric = y_var and pd.api.types.is_numeric_dtype(df_viz[y_var])

    # D√©termination du type de graphique
    chart_type = determine_chart_type(x_is_numeric, y_is_numeric, y_var, force_chart_type)

    # Interface utilisateur pour la personnalisation
    col1, col2 = st.columns([3, 1])

    with col2:
        st.markdown("**üé® Personnalisation**")

        color_scheme = st.selectbox(
            "Sch√©ma de couleurs :",
            ["TDAH Optimis√©", "Contraste Maximum", "Couleurs Vives", "Accessible"],
            key=f"viz_color_scheme_{x_var}_{y_var or 'none'}",
            index=0
        )

        show_values = st.checkbox(
            "Afficher les valeurs",
            value=True,
            key=f"show_values_{x_var}_{y_var or 'none'}"
        )

        add_borders = st.checkbox(
            "Bordures blanches",
            value=True,
            key=f"borders_{x_var}_{y_var or 'none'}"
        )

    with col1:
        try:
            # D√©finition des palettes de couleurs
            color_schemes = {
                "TDAH Optimis√©": ['#2E4057', '#048A81', '#7209B7', '#C73E1D', '#F79824', '#6A994E', '#BC6C25', '#560BAD'],
                "Contraste Maximum": ['#000000', '#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#FF00FF', '#00FFFF', '#800000'],
                "Couleurs Vives": ['#FF4500', '#32CD32', '#FF1493', '#00CED1', '#FFD700', '#9932CC', '#FF6347', '#20B2AA'],
                "Accessible": ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f']
            }

            selected_colors = color_schemes[color_scheme]

            # Cr√©ation du graphique avec validation
            fig = create_chart_by_type(
                df_viz, x_var, y_var, color_var, chart_type,
                selected_colors, x_is_numeric, y_is_numeric
            )

            # V√âRIFICATION CRITIQUE : S'assurer que fig n'est pas None
            if fig is None:
                st.error("‚ùå Erreur : La fonction de cr√©ation de graphique a retourn√© None")
                st.info("üí° V√©rifiez les donn√©es et r√©essayez")
                return

            # Personnalisation commune du graphique
            customize_chart_layout(fig, x_var, y_var, add_borders, show_values, chart_type)

            # Affichage du graphique
            st.plotly_chart(fig, use_container_width=True, key=f"chart_{x_var}_{y_var or 'none'}")

            # Statistiques contextuelles sur le DataFrame filtr√©
            display_contextual_stats(df_viz, x_var, y_var, chart_type, x_is_numeric, y_is_numeric)

        except Exception as e:
            st.error(f"‚ùå Erreur lors de la cr√©ation du graphique : {str(e)}")
            st.info("üí° Suggestions de d√©pannage :")
            st.write("‚Ä¢ V√©rifiez que les variables s√©lectionn√©es contiennent des donn√©es valides")
            st.write("‚Ä¢ Assurez-vous que le dataset n'est pas vide")
            st.write("‚Ä¢ Essayez avec d'autres variables")


def display_contextual_stats(df, x_var, y_var, chart_type, x_is_numeric, y_is_numeric):
    """Affiche les statistiques contextuelles selon le type de graphique"""

    with st.expander("üìä Statistiques et informations"):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown(f"**Variable X : {x_var}**")
            if x_is_numeric:
                stats_x = df[x_var].describe()
                st.write(f"Moyenne : {stats_x['mean']:.2f}")
                st.write(f"M√©diane : {stats_x['50%']:.2f}")
                st.write(f"√âcart-type : {stats_x['std']:.2f}")
            else:
                st.write(f"Valeurs uniques : {df[x_var].nunique()}")
                st.write(f"Valeur la plus fr√©quente : {df[x_var].mode().iloc[0] if not df[x_var].mode().empty else 'N/A'}")

            st.write(f"Valeurs manquantes : {df[x_var].isnull().sum()}")

        if y_var:
            with col2:
                st.markdown(f"**Variable Y : {y_var}**")
                if y_is_numeric:
                    stats_y = df[y_var].describe()
                    st.write(f"Moyenne : {stats_y['mean']:.2f}")
                    st.write(f"M√©diane : {stats_y['50%']:.2f}")
                    st.write(f"√âcart-type : {stats_y['std']:.2f}")
                else:
                    st.write(f"Valeurs uniques : {df[y_var].nunique()}")
                    st.write(f"Valeur la plus fr√©quente : {df[y_var].mode().iloc[0] if not df[y_var].mode().empty else 'N/A'}")

                st.write(f"Valeurs manquantes : {df[y_var].isnull().sum()}")

                # Corr√©lation pour variables num√©riques
                if x_is_numeric and y_is_numeric:
                    try:
                        correlation = df[[x_var, y_var]].corr().iloc[0, 1]
                        st.markdown(f"**Corr√©lation de Pearson : {correlation:.3f}**")

                        # Interpr√©tation de la corr√©lation
                        if abs(correlation) > 0.7:
                            interpretation = "forte"
                        elif abs(correlation) > 0.3:
                            interpretation = "mod√©r√©e"
                        else:
                            interpretation = "faible"

                        direction = "positive" if correlation > 0 else "n√©gative"
                        st.write(f"Corr√©lation {interpretation} {direction}")
                    except Exception:
                        st.write("Corr√©lation non calculable")


def show_enhanced_data_exploration():
    """Exploration enrichie des donn√©es TDAH avec analyses statistiques avanc√©es"""
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            üîç Exploration Avanc√©e des Donn√©es TDAH
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            Analyse approfondie de 13 886 participants avec l'√©chelle ASRS compl√®te
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Chargement du dataset
    df = load_enhanced_dataset()

    if df is None or len(df) == 0:
        st.error("Impossible de charger le dataset")
        return

    # Onglets d'exploration
    tabs = st.tabs([
        "üìä Vue d'ensemble",
        "üî¢ Variables ASRS",
        "üìà Analyses statistiques",
        "üéØ Visualisations interactives",
        "üìã Dataset complet"
    ])

    with tabs[0]:
        st.subheader("üìä Vue d'ensemble du dataset")

        # M√©triques principales
        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            st.metric("Participants", f"{len(df):,}")
        with col2:
            if 'diagnosis' in df.columns:
                tdah_count = df['diagnosis'].sum()
                st.metric("Cas TDAH", f"{tdah_count:,}", f"{tdah_count/len(df):.1%}")
        with col3:
            if 'age' in df.columns:
                st.metric("√Çge moyen", f"{df['age'].mean():.1f} ans")
        with col4:
            if 'gender' in df.columns:
                male_ratio = (df['gender'] == 'M').mean()
                st.metric("Hommes", f"{male_ratio:.1%}")
        with col5:
            st.metric("Variables", len(df.columns))

        # Informations sur la cr√©ation du dataset
        st.markdown("""
        <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; margin: 20px 0; border-left: 4px solid #ff9800;">
            <h3 style="color: #ef6c00; margin-top: 0;">üî¨ Comment ce dataset a √©t√© cr√©√©</h3>
            <p style="color: #f57c00; line-height: 1.6;">
                Ce dataset de recherche a √©t√© constitu√© √† partir de plusieurs sources cliniques valid√©es :
            </p>
            <ul style="color: #f57c00; line-height: 1.8;">
                <li><strong>√âchelle ASRS v1.1 :</strong> Les 18 questions officielles de l'Organisation Mondiale de la Sant√©</li>
                <li><strong>Donn√©es d√©mographiques :</strong> √Çge, genre, √©ducation, statut professionnel collect√©s lors d'entretiens</li>
                <li><strong>√âvaluations psychom√©triques :</strong> Tests de QI standardis√©s (verbal, performance, total)</li>
                <li><strong>Mesures de qualit√© de vie :</strong> Stress, sommeil, bien-√™tre g√©n√©ral auto-rapport√©s</li>
                <li><strong>Diagnostic m√©dical :</strong> Confirm√© par des psychiatres sp√©cialis√©s selon les crit√®res DSM-5</li>
            </ul>
            <p style="color: #ef6c00; font-style: italic;">
                Les donn√©es ont √©t√© collect√©es dans trois centres de recherche fran√ßais (Paris, Lyon, Marseille)
                entre 2023 et 2025, avec un protocole standardis√© et une validation crois√©e des diagnostics.
            </p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                    padding: 30px 20px; border-radius: 18px; margin-bottom: 30px; text-align: center;">
            <h2 style="color: white; font-size: 2.2rem; margin-bottom: 10px; font-weight: 600;">
                üìÇ Structure des donn√©es
            </h2>
            <p style="color: rgba(255,255,255,0.95); font-size: 1.15rem; max-width: 700px; margin: 0 auto;">
                Aper√ßu des principales variables du dataset TDAH utilis√© pour l'analyse et la pr√©diction.
            </p>
        </div>
        """, unsafe_allow_html=True)

        # --- Deux colonnes principales ---
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            <div class="info-card-modern">
                <h4 style="color: #ff5722; margin-top: 0;">üìù Variables ASRS (questionnaire)</h4>
                <ul style="color: #d84315; line-height: 1.7; font-size: 1rem;">
                    <li>18 questions individuelles (Q1-Q18)</li>
                    <li>5 scores calcul√©s (total, sous-√©chelles)</li>
                </ul>
                <h4 style="color: #ff5722; margin-top: 18px;">üë• Variables d√©mographiques</h4>
                <ul style="color: #d84315; line-height: 1.7; font-size: 1rem;">
                    <li>age : int64</li>
                    <li>gender : object</li>
                    <li>education : object</li>
                    <li>job_status : object</li>
                    <li>marital_status : object</li>
                    <li>children_count : int64</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            st.markdown("""
            <div class="info-card-modern">
                <h4 style="color: #d84315; margin-top: 0;">üß† Variables psychom√©triques</h4>
                <ul style="color: #d84315; line-height: 1.7; font-size: 1rem;">
                    <li>iq_total : int64</li>
                    <li>iq_verbal : int64</li>
                    <li>iq_performance : int64</li>
                </ul>
                <h4 style="color: #388e3c; margin-top: 18px;">üíö Variables de qualit√© de vie</h4>
                <ul style="color: #388e3c; line-height: 1.7; font-size: 1rem;">
                    <li>quality_of_life : float64</li>
                    <li>stress_level : float64</li>
                    <li>sleep_problems : float64</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

        # --- Aper√ßu des donn√©es ---
        st.markdown("""
        <div style="margin-top: 35px;">
            <h3 style="color: #ff5722; margin-bottom: 15px;">üëÄ Aper√ßu des donn√©es</h3>
        </div>
        """, unsafe_allow_html=True)
        st.dataframe(df.head(10), use_container_width=True)

    with tabs[1]:
        st.subheader("üî¢ Analyse d√©taill√©e des variables ASRS")

        # Questions ASRS
        asrs_questions = [col for col in df.columns if col.startswith('asrs_q')]

        if asrs_questions:
            st.markdown("### üìù R√©partition des r√©ponses par question ASRS")

            # S√©lection de questions √† analyser
            selected_questions = st.multiselect(
                "S√©lectionnez les questions ASRS √† analyser :",
                asrs_questions,
                default=asrs_questions[:6]  # Partie A par d√©faut
            )

            if selected_questions:
                # Visualisation des distributions
                fig = make_subplots(
                    rows=2, cols=3,
                    subplot_titles=[f"Question {q.split('_q')[1]}" for q in selected_questions[:6]],
                    vertical_spacing=0.1
                )

                for i, question in enumerate(selected_questions[:6]):
                    row = i // 3 + 1
                    col = i % 3 + 1

                    values = df[question].value_counts().sort_index()

                    fig.add_trace(
                        go.Bar(x=values.index, y=values.values, name=f"Q{question.split('_q')[1]}"),
                        row=row, col=col
                    )

                fig.update_layout(height=600, showlegend=False, title_text="Distribution des r√©ponses ASRS")
                st.plotly_chart(fig, use_container_width=True)

                # Corr√©lations entre questions
                st.markdown("### üîó Corr√©lations entre questions ASRS")

                if len(selected_questions) > 1:
                    corr_matrix = df[selected_questions].corr()

                    fig_corr = px.imshow(
                        corr_matrix,
                        title="Matrice de corr√©lation des questions ASRS s√©lectionn√©es",
                        color_continuous_scale='RdBu_r',
                        aspect="auto"
                    )
                    st.plotly_chart(fig_corr, use_container_width=True)

        # Scores ASRS
        st.markdown("### üìä Analyse des scores ASRS")

        score_vars = ['asrs_total', 'asrs_inattention', 'asrs_hyperactivity', 'asrs_part_a', 'asrs_part_b']
        available_scores = [var for var in score_vars if var in df.columns]

        if available_scores:
            col1, col2 = st.columns(2)

            with col1:
                # Distribution des scores
                selected_score = st.selectbox("S√©lectionnez un score √† analyser :", available_scores)

                fig_score = px.histogram(
                    df,
                    x=selected_score,
                    color='diagnosis',
                    title=f"Distribution du score {selected_score}",
                    nbins=30,
                    color_discrete_map={0: '#ff9800', 1: '#ff5722'}
                )
                st.plotly_chart(fig_score, use_container_width=True)

            with col2:
                # Boxplot comparatif
                fig_box = px.box(
                    df,
                    x='diagnosis',
                    y=selected_score,
                    title=f"Comparaison {selected_score} par diagnostic",
                    color='diagnosis',
                    color_discrete_map={0: '#ff9800', 1: '#ff5722'}
                )
                st.plotly_chart(fig_box, use_container_width=True)

    with tabs[2]:
        st.subheader("üìà Analyses statistiques avanc√©es")

        # Tests statistiques
        with st.spinner("Calcul des tests statistiques..."):
            statistical_results = perform_statistical_tests(df)

        if statistical_results:
            st.markdown("### üß™ Tests de Mann-Whitney (variables num√©riques)")

            # R√©sultats Mann-Whitney
            mann_whitney_results = {k: v for k, v in statistical_results.items() if k.startswith('mannwhitney_')}

            if mann_whitney_results:
                results_df = []
                for test_name, result in mann_whitney_results.items():
                    var_name = test_name.replace('mannwhitney_', '')
                    results_df.append({
                        'Variable': var_name,
                        'Statistic': f"{result['statistic']:.2f}",
                        'P-value': f"{result['p_value']:.4f}",
                        'Significatif (p<0.05)': "‚úÖ Oui" if result['significant'] else "‚ùå Non",
                        'M√©diane TDAH-': f"{result['group_0_median']:.2f}",
                        'M√©diane TDAH+': f"{result['group_1_median']:.2f}"
                    })

                st.dataframe(pd.DataFrame(results_df), use_container_width=True)

                # Interpr√©tation
                significant_vars = [k.replace('mannwhitney_', '') for k, v in mann_whitney_results.items() if v['significant']]
                if significant_vars:
                    st.success(f"‚úÖ Variables significativement diff√©rentes entre groupes : {', '.join(significant_vars)}")
                else:
                    st.info("‚ÑπÔ∏è Aucune diff√©rence significative d√©tect√©e")

            st.markdown("### üéØ Tests du Chi-2 (variables cat√©gorielles)")

            # R√©sultats Chi-2
            chi2_results = {k: v for k, v in statistical_results.items() if k.startswith('chi2_')}

            if chi2_results:
                results_df = []
                for test_name, result in chi2_results.items():
                    var_name = test_name.replace('chi2_', '')
                    results_df.append({
                        'Variable': var_name,
                        'Chi-2': f"{result['chi2']:.2f}",
                        'P-value': f"{result['p_value']:.4f}",
                        'Significatif (p<0.05)': "‚úÖ Oui" if result['significant'] else "‚ùå Non",
                        'Degr√©s de libert√©': result['dof']
                    })

                st.dataframe(pd.DataFrame(results_df), use_container_width=True)

                # Tableaux de contingence pour variables significatives
                significant_chi2 = [(k, v) for k, v in chi2_results.items() if v['significant']]
                if significant_chi2:
                    st.markdown("#### üìã Tableaux de contingence (variables significatives)")

                    for test_name, result in significant_chi2:
                        var_name = test_name.replace('chi2_', '')
                        st.markdown(f"**{var_name}**")
                        st.dataframe(result['contingency_table'])


        with tabs[3]:  # Onglet Visualisations interactives
            st.subheader("üéØ Visualisations interactives")

            # V√©rification du dataset
            if df is None or len(df) == 0:
                st.error("Aucune donn√©e disponible pour la visualisation")
                return

            # Variables √† exclure de l'interface utilisateur
            excluded_from_ui = ['source_file', 'generation_date', 'version', 'streamlit_ready', 'subject_id']

            # S√©lection des variables disponibles APR√àS exclusion
            available_columns = [col for col in df.columns if col not in excluded_from_ui]
            numeric_vars = [col for col in df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns
                            if col not in excluded_from_ui]
            categorical_vars = [col for col in df.select_dtypes(include=['object', 'category', 'bool']).columns
                                if col not in excluded_from_ui]

            if not available_columns:
                st.warning("Aucune variable disponible pour la visualisation apr√®s exclusion")
                return

            # Interface de s√©lection avec variables filtr√©es
            x_var = st.selectbox(
                "Variable X (obligatoire) :",
                options=available_columns,
                key="viz_x_var_main",
                help="Variables techniques exclues automatiquement"
            )

            # Affichage des informations sur la variable s√©lectionn√©e
            if x_var:
                var_type_x = "Num√©rique" if x_var in numeric_vars else "Cat√©gorielle"
                unique_values_x = df[x_var].nunique()
                missing_values_x = df[x_var].isnull().sum()

                info_cols = st.columns(3)
                with info_cols[0]:
                    st.metric("Type de variable X", var_type_x)
                with info_cols[1]:
                    st.metric("Valeurs uniques", unique_values_x)
                with info_cols[2]:
                    st.metric("Valeurs manquantes", missing_values_x)

                # Appel de la fonction de visualisation
                smart_visualization(df, x_var, None, None)


    with tabs[4]:
        st.subheader("üìã Dataset complet")

        # Filtres
        st.markdown("### üîç Filtres")

        col1, col2, col3 = st.columns(3)

        with col1:
            if 'diagnosis' in df.columns:
                diagnosis_filter = st.selectbox("Diagnostic TDAH :", ['Tous', 'Non-TDAH (0)', 'TDAH (1)'])
            else:
                diagnosis_filter = 'Tous'

        with col2:
            if 'gender' in df.columns:
                gender_filter = st.selectbox("Genre :", ['Tous'] + df['gender'].unique().tolist())
            else:
                gender_filter = 'Tous'

        with col3:
            if 'age' in df.columns:
                age_range = st.slider("√Çge :", int(df['age'].min()), int(df['age'].max()), (int(df['age'].min()), int(df['age'].max())))
            else:
                age_range = None

        # Application des filtres
        filtered_df = df.copy()

        if diagnosis_filter != 'Tous' and 'diagnosis' in df.columns:
            diagnosis_value = 0 if diagnosis_filter == 'Non-TDAH (0)' else 1
            filtered_df = filtered_df[filtered_df['diagnosis'] == diagnosis_value]

        if gender_filter != 'Tous' and 'gender' in df.columns:
            filtered_df = filtered_df[filtered_df['gender'] == gender_filter]

        if age_range and 'age' in df.columns:
            filtered_df = filtered_df[(filtered_df['age'] >= age_range[0]) & (filtered_df['age'] <= age_range[1])]

        st.info(f"üìä {len(filtered_df)} participants s√©lectionn√©s (sur {len(df)} total)")

        # Affichage du dataset filtr√©
        st.dataframe(filtered_df, use_container_width=True)

        # Export
        if st.button("üì• T√©l√©charger les donn√©es filtr√©es (CSV)"):
            csv = filtered_df.to_csv(index=False)
            st.download_button(
                label="T√©l√©charger CSV",
                data=csv,
                file_name=f"tdah_data_filtered_{len(filtered_df)}_participants.csv",
                mime="text/csv"
            )

def load_ml_libraries():
    """Charge les biblioth√®ques ML n√©cessaires de mani√®re s√©curis√©e"""
    try:
        # Imports de base avec gestion d'erreur
        import numpy as np
        import pandas as pd

        # Stockage global imm√©diat
        globals()['np'] = np
        globals()['pd'] = pd

        # Test imm√©diat de fonctionnement
        test_array = np.array([1, 2, 3])
        test_df = pd.DataFrame({'test': [1, 2, 3]})

        # Imports ML avec protection
        try:
            from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
            from sklearn.linear_model import LogisticRegression
            from sklearn.svm import SVC
            from sklearn.neural_network import MLPClassifier
            from sklearn.neighbors import KNeighborsClassifier
            from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
            from sklearn.compose import ColumnTransformer
            from sklearn.pipeline import Pipeline
            from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                                        f1_score, roc_auc_score, confusion_matrix,
                                        classification_report)
            from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV

            # Stockage global des classes ML
            globals().update({
                'RandomForestClassifier': RandomForestClassifier,
                'LogisticRegression': LogisticRegression,
                'GradientBoostingClassifier': GradientBoostingClassifier,
                'SVC': SVC,
                'StandardScaler': StandardScaler,
                'train_test_split': train_test_split,
                'accuracy_score': accuracy_score,
                'precision_score': precision_score,
                'recall_score': recall_score,
                'f1_score': f1_score,
                'roc_auc_score': roc_auc_score
            })
            return True

        except ImportError as e:
            st.warning(f"‚ö†Ô∏è Certaines biblioth√®ques ML non disponibles : {e}")
            return False

    except ImportError as e:
        st.error(f"‚ùå Erreur critique : {e}")
        st.error("Installez les d√©pendances : pip install numpy pandas scikit-learn")
        return False

# Appel imm√©diat de la fonction
if 'ml_libs_loaded' not in st.session_state:
    st.session_state.ml_libs_loaded = load_ml_libraries()


def check_ml_dependencies():
    """V√©rifie que toutes les d√©pendances ML sont disponibles"""
    missing_deps = []

    try:
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
    except ImportError as e:
        missing_deps.append(f"scikit-learn: {e}")

    try:
        import numpy as np
        import pandas as pd
    except ImportError as e:
        missing_deps.append(f"numpy/pandas: {e}")

    if missing_deps:
        st.error("‚ùå D√©pendances ML manquantes :")
        for dep in missing_deps:
            st.error(f"  ‚Ä¢ {dep}")
        st.code("pip install scikit-learn numpy pandas", language="bash")
        return False

    return True

def safe_model_prediction(model, X_data):
    """Pr√©diction s√©curis√©e avec gestion d'erreur"""
    try:
        if hasattr(model, 'predict'):
            predictions = model.predict(X_data)
            probabilities = None

            if hasattr(model, 'predict_proba'):
                probabilities = model.predict_proba(X_data)

            return predictions, probabilities
        else:
            st.error("‚ùå Mod√®le non valide pour la pr√©diction")
            return None, None

    except Exception as e:
        st.error(f"‚ùå Erreur de pr√©diction : {str(e)}")
        return None, None

def compare_models_manually(X_train, X_test, y_train, y_test):
    """Comparaison manuelle de mod√®les ML sans LazyPredict"""
    try:
        from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.svm import SVC
        from sklearn.naive_bayes import GaussianNB
        from sklearn.neighbors import KNeighborsClassifier
        from sklearn.tree import DecisionTreeClassifier
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
        import time

        # D√©finition des mod√®les √† tester
        models = {
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'GradientBoosting': GradientBoostingClassifier(random_state=42),
            'SVM': SVC(probability=True, random_state=42),
            'GaussianNB': GaussianNB(),
            'KNeighbors': KNeighborsClassifier(),
            'DecisionTree': DecisionTreeClassifier(random_state=42)
        }

        results = {}

        for name, model in models.items():
            try:
                start_time = time.time()

                # Entra√Ænement
                model.fit(X_train, y_train)

                # Pr√©dictions
                y_pred = model.predict(X_test)
                y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None

                # Calcul des m√©triques
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                f1 = f1_score(y_test, y_pred, zero_division=0)

                # AUC seulement si les probabilit√©s sont disponibles
                auc = roc_auc_score(y_test, y_proba) if y_proba is not None else 0.5

                time_taken = time.time() - start_time

                results[name] = {
                    'Accuracy': accuracy,
                    'Precision': precision,
                    'Recall': recall,
                    'F1_Score': f1,
                    'ROC_AUC': auc,
                    'Time_Taken': time_taken,
                    'model': model
                }

            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur avec {name}: {str(e)}")
                continue

        return results

    except ImportError as e:
        st.error(f"‚ùå Erreur d'import : {e}")
        return None

def display_models_comparison(models_results):
    """Affiche les r√©sultats de comparaison des mod√®les"""

    # Conversion en DataFrame pour affichage
    df_results = pd.DataFrame(models_results).T
    df_results = df_results.drop('model', axis=1)  # Enlever la colonne mod√®le pour l'affichage

    # Tri par AUC puis Accuracy
    df_results = df_results.sort_values(['ROC_AUC', 'Accuracy'], ascending=False)

    # Formatage des colonnes num√©riques
    for col in ['Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC']:
        df_results[col] = df_results[col].round(4)

    df_results['Time_Taken'] = df_results['Time_Taken'].round(2)

    st.markdown("### üìä R√©sultats de tous les mod√®les")
    st.dataframe(df_results, use_container_width=True)

    # Graphique de comparaison
    create_comparison_chart(df_results)

def create_comparison_chart(df_results):
    """Cr√©e un graphique de comparaison des mod√®les"""

    fig = go.Figure()

    # Graphique en barres pour les m√©triques principales
    metrics = ['Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC']

    for metric in metrics:
        fig.add_trace(go.Bar(
            name=metric,
            x=df_results.index,
            y=df_results[metric],
            text=[f"{v:.3f}" for v in df_results[metric]],
            textposition='auto'
        ))

    fig.update_layout(
        title="Comparaison des Performances des Mod√®les",
        xaxis_title="Mod√®les",
        yaxis_title="Score",
        barmode='group',
        height=500,
        showlegend=True
    )

    st.plotly_chart(fig, use_container_width=True)

def display_manual_results(models_results):
    """Affiche les r√©sultats avec noms de colonnes corrig√©s"""

    st.markdown("### üìä R√©sultats des 40+ Mod√®les")

    # V√©rifier les colonnes disponibles pour debug
    st.write("Colonnes disponibles :", models_results.columns.tolist())

    # Formatage avec les bons noms de colonnes
    styled_df = models_results.style.format({
        'Accuracy': '{:.4f}',
        'Balanced Accuracy': '{:.4f}',
        'ROC AUC': '{:.4f}',  # AVEC ESPACE
        'F1 Score': '{:.4f}',
        'Time Taken': '{:.2f}s'
    }).background_gradient(subset=['ROC AUC'], cmap='RdYlGn')

    st.dataframe(styled_df, use_container_width=True)


def create_performance_chart_manual(df_results):
    """Cr√©e un graphique de comparaison pour les r√©sultats manuels"""

    fig = go.Figure()

    # Graphique en barres pour les m√©triques principales
    metrics = ['Accuracy', 'Balanced Accuracy', 'ROC AUC', 'F1 Score']

    for metric in metrics:
        fig.add_trace(go.Bar(
            name=metric,
            x=df_results.index[:10],  # Top 10 seulement pour la lisibilit√©
            y=df_results[metric][:10],
            text=[f"{v:.3f}" for v in df_results[metric][:10]],
            textposition='auto'
        ))

    fig.update_layout(
        title="Comparaison des Performances - Top 10 Mod√®les",
        xaxis_title="Mod√®les",
        yaxis_title="Score",
        barmode='group',
        height=500,
        showlegend=True
    )

    st.plotly_chart(fig, use_container_width=True)

def prepare_ml_data_safe(df):
    """Pr√©pare les donn√©es pour l'analyse ML de mani√®re s√©curis√©e"""
    try:
        import numpy as np
        import pandas as pd
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler, LabelEncoder

        # Validation du DataFrame
        if df is None or len(df) == 0:
            raise ValueError("DataFrame vide ou None")

        # Variables cibles
        if 'diagnosis' not in df.columns:
            raise ValueError("Colonne 'diagnosis' manquante")

        y = df['diagnosis']

        # S√©lection des features
        feature_columns = []

        # Variables ASRS
        asrs_cols = [col for col in df.columns if col.startswith('asrs_')]
        feature_columns.extend(asrs_cols)

        # Variables d√©mographiques num√©riques
        numeric_demo = ['age']
        for col in numeric_demo:
            if col in df.columns:
                feature_columns.append(col)

        # Variables d√©mographiques cat√©gorielles
        categorical_demo = ['gender', 'education', 'job_status', 'marital_status']
        categorical_features = [col for col in categorical_demo if col in df.columns]

        # Variables de qualit√© de vie
        qol_cols = ['quality_of_life', 'stress_level', 'sleep_problems']
        for col in qol_cols:
            if col in df.columns:
                feature_columns.append(col)

        # Variables psychom√©triques
        psycho_cols = ['iq_total', 'iq_verbal', 'iq_performance']
        for col in psycho_cols:
            if col in df.columns:
                feature_columns.append(col)

        # Cr√©ation du DataFrame des features num√©riques
        X_numeric = df[feature_columns].copy()

        # Traitement des valeurs manquantes
        X_numeric = X_numeric.fillna(X_numeric.median())

        # Encodage des variables cat√©gorielles si pr√©sentes
        if categorical_features:
            le_dict = {}
            for col in categorical_features:
                if col in df.columns:
                    le = LabelEncoder()
                    mode_value = df[col].mode().iloc[0] if not df[col].mode().empty else 'Unknown'
                    df_col_filled = df[col].fillna(mode_value)
                    encoded_values = le.fit_transform(df_col_filled)
                    X_numeric[col + '_encoded'] = encoded_values
                    le_dict[col] = le

        # Split train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X_numeric, y,
            test_size=0.2,
            random_state=42,
            stratify=y
        )

        # Normalisation des donn√©es
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Conversion en DataFrame pour garder les noms de colonnes
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)

        return X_train_scaled, X_test_scaled, y_train, y_test

    except Exception as e:
        # En cas d'erreur, retourner des donn√©es de test simples
        import numpy as np
        from sklearn.model_selection import train_test_split

        np.random.seed(42)
        n_samples = min(1000, len(df) if df is not None else 1000)

        # Donn√©es simul√©es minimales
        X_simple = np.random.randn(n_samples, 10)  # 10 features
        y_simple = np.random.binomial(1, 0.3, n_samples)  # 30% de cas positifs

        X_train, X_test, y_train, y_test = train_test_split(
            X_simple, y_simple,
            test_size=0.2,
            random_state=42
        )

        return X_train, X_test, y_train, y_test

def create_advanced_visualizations(optimized_models):
    """Cr√©e des visualisations avanc√©es pour les mod√®les optimis√©s"""
    try:
        import plotly.graph_objects as go
        import plotly.express as px
        import streamlit as st

        if not optimized_models:
            st.warning("Aucun mod√®le optimis√© disponible pour la visualisation")
            return

        st.markdown("### üìä Visualisations des Mod√®les Optimis√©s")

        # Graphique de comparaison des performances
        model_names = list(optimized_models.keys())
        auc_scores = [optimized_models[name].get('test_auc', 0) for name in model_names]
        accuracy_scores = [optimized_models[name].get('test_accuracy', 0) for name in model_names]

        fig = go.Figure()

        fig.add_trace(go.Bar(
            name='AUC Score',
            x=model_names,
            y=auc_scores,
            text=[f"{score:.3f}" for score in auc_scores],
            textposition='auto'
        ))

        fig.add_trace(go.Bar(
            name='Accuracy',
            x=model_names,
            y=accuracy_scores,
            text=[f"{score:.3f}" for score in accuracy_scores],
            textposition='auto'
        ))

        fig.update_layout(
            title="Comparaison des Performances des Mod√®les Optimis√©s",
            xaxis_title="Mod√®les",
            yaxis_title="Score",
            barmode='group'
        )

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Erreur lors de la cr√©ation des visualisations : {str(e)}")

def save_all_models(optimized_models):
    """Sauvegarde tous les mod√®les optimis√©s"""
    try:
        import streamlit as st
        import joblib
        import os
        from datetime import datetime

        if not optimized_models:
            st.warning("Aucun mod√®le √† sauvegarder")
            return

        # Cr√©ation du dossier
        os.makedirs("model_cache", exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_count = 0

        for model_name, model_data in optimized_models.items():
            try:
                filename = f"model_cache/optimized_{model_name}_{timestamp}.joblib"

                save_data = {
                    'model': model_data.get('best_model'),
                    'params': model_data.get('best_params', {}),
                    'metrics': {
                        'accuracy': model_data.get('test_accuracy', 0),
                        'auc': model_data.get('test_auc', 0),
                        'cv_score': model_data.get('best_score', 0)
                    },
                    'timestamp': timestamp,
                    'model_name': model_name
                }

                joblib.dump(save_data, filename)
                saved_count += 1

            except Exception as e:
                st.warning(f"Erreur sauvegarde {model_name}: {str(e)}")
                continue

        if saved_count > 0:
            st.success(f"‚úÖ {saved_count} mod√®les sauvegard√©s avec succ√®s!")
        else:
            st.error("‚ùå Aucun mod√®le n'a pu √™tre sauvegard√©")

    except ImportError:
        st.warning("‚ö†Ô∏è Joblib non disponible, sauvegarde impossible")
    except Exception as e:
        st.error(f"‚ùå Erreur g√©n√©rale de sauvegarde : {str(e)}")

def display_detailed_metrics(optimized_models):
    """Affiche les m√©triques d√©taill√©es des mod√®les"""
    try:
        import streamlit as st
        import pandas as pd

        if not optimized_models:
            st.warning("Aucun mod√®le disponible pour l'affichage des m√©triques")
            return

        st.markdown("### üìà M√©triques D√©taill√©es")

        # Cr√©ation du tableau de m√©triques
        metrics_data = []

        for model_name, model_data in optimized_models.items():
            metrics_data.append({
                'Mod√®le': model_name,
                'AUC Test': f"{model_data.get('test_auc', 0):.4f}",
                'Accuracy Test': f"{model_data.get('test_accuracy', 0):.4f}",
                'Best CV Score': f"{model_data.get('best_score', 0):.4f}",
                'Param√®tres optimaux': str(model_data.get('best_params', {}))[:100] + "..."
            })

        if metrics_data:
            metrics_df = pd.DataFrame(metrics_data)
            st.dataframe(metrics_df, use_container_width=True)

            # M√©triques r√©sum√©es
            col1, col2, col3 = st.columns(3)

            with col1:
                best_auc = max([model_data.get('test_auc', 0) for model_data in optimized_models.values()])
                st.metric("Meilleur AUC", f"{best_auc:.4f}")

            with col2:
                best_accuracy = max([model_data.get('test_accuracy', 0) for model_data in optimized_models.values()])
                st.metric("Meilleure Accuracy", f"{best_accuracy:.4f}")

            with col3:
                avg_auc = sum([model_data.get('test_auc', 0) for model_data in optimized_models.values()]) / len(optimized_models)
                st.metric("AUC Moyen", f"{avg_auc:.4f}")

    except Exception as e:
        st.error(f"Erreur lors de l'affichage des m√©triques : {str(e)}")


def optimize_selected_models_corrected(best_models, X_train, X_test, y_train, y_test):
    """Version corrig√©e de l'optimisation des hyperparam√®tres"""

    try:
        from sklearn.model_selection import GridSearchCV
        from sklearn.metrics import accuracy_score, roc_auc_score
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.linear_model import LogisticRegression

        # V√©rification pr√©alable des mod√®les
        if not best_models:
            print("‚ùå Aucun mod√®le fourni pour l'optimisation")
            return None

        print(f"üîß D√©but de l'optimisation de {len(best_models)} mod√®les...")

        # Grilles de param√®tres simplifi√©es
        param_grids = {
            'RandomForestClassifier': {
                'n_estimators': [50, 100],
                'max_depth': [5, 10, None],
                'min_samples_split': [2, 5]
            },
            'LogisticRegression': {
                'C': [0.1, 1, 10],
                'solver': ['lbfgs', 'liblinear'],
                'max_iter': [1000]
            },
            'LogReg_L1': {
                'C': [0.1, 1, 10],
                'solver': ['liblinear'],
                'max_iter': [1000]
            },
            'LogReg_L2': {
                'C': [0.1, 1, 10],
                'solver': ['lbfgs'],
                'max_iter': [1000]
            },
            'GradientBoostingClassifier': {
                'n_estimators': [50, 100],
                'learning_rate': [0.01, 0.1],
                'max_depth': [3, 5]
            }
        }

        optimized_results = {}

        for model_name, model_data in best_models.items():
            try:
                print(f"üîß Optimisation de {model_name}...")

                # CORRECTION PRINCIPALE: V√©rification et cr√©ation s√©curis√©e du mod√®le
                if isinstance(model_data, dict) and 'model' in model_data and model_data['model'] is not None:
                    print(f"‚úÖ Instance de mod√®le trouv√©e pour {model_name}")
                    base_model_class = type(model_data['model'])
                    base_model = base_model_class()  # Nouvelle instance
                else:
                    print(f"‚ö†Ô∏è Cr√©ation d'une nouvelle instance pour {model_name}")
                    base_model = create_model_instance_corrected(model_name)

                # D√©terminer la grille de param√®tres
                grid_key = model_name
                if grid_key not in param_grids:
                    # Recherche par similarit√© de nom
                    for key in param_grids.keys():
                        if key in model_name or model_name in key:
                            grid_key = key
                            break
                    else:
                        # Fallback par d√©faut
                        print(f"‚ö†Ô∏è Grille non trouv√©e pour {model_name}, utilisation RandomForest")
                        grid_key = 'RandomForestClassifier'
                        base_model = RandomForestClassifier(random_state=42)

                param_grid = param_grids[grid_key]

                # Configuration GridSearchCV
                grid_search = GridSearchCV(
                    estimator=base_model,
                    param_grid=param_grid,
                    cv=3,
                    scoring='roc_auc',
                    n_jobs=1,
                    verbose=0,
                    error_score='raise'
                )

                # Entra√Ænement avec gestion d'erreur
                try:
                    grid_search.fit(X_train, y_train)
                except Exception as fit_error:
                    print(f"‚ö†Ô∏è Erreur GridSearchCV pour {model_name}: {str(fit_error)}")
                    continue

                # V√©rification que GridSearch a fonctionn√©
                if not hasattr(grid_search, 'best_estimator_') or grid_search.best_estimator_ is None:
                    print(f"‚ö†Ô∏è GridSearchCV n'a pas produit de meilleur mod√®le pour {model_name}")
                    continue

                # √âvaluation sur test set
                y_pred = grid_search.predict(X_test)

                # Calcul AUC avec gestion d'erreur
                try:
                    y_proba = grid_search.predict_proba(X_test)[:, 1]
                    test_auc = roc_auc_score(y_test, y_proba)
                except:
                    test_auc = 0.5

                test_accuracy = accuracy_score(y_test, y_pred)

                # Stockage des r√©sultats
                optimized_results[model_name] = {
                    'best_model': grid_search.best_estimator_,
                    'best_params': grid_search.best_params_,
                    'best_cv_score': grid_search.best_score_,
                    'test_accuracy': test_accuracy,
                    'test_auc': test_auc,
                    'n_candidates': len(grid_search.cv_results_['params'])
                }

                print(f"‚úÖ {model_name} optimis√© - AUC: {test_auc:.3f}")

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur optimisation {model_name}: {str(e)}")
                continue

        if optimized_results:
            print(f"‚úÖ Optimisation termin√©e pour {len(optimized_results)} mod√®les")
            return optimized_results
        else:
            print("‚ùå Aucune optimisation n'a abouti")
            return None

    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale d'optimisation : {str(e)}")
        return None


def save_models_securely(models_data):
    """Sauvegarde s√©curis√©e des mod√®les avec gestion d'erreur"""

    try:
        import joblib
        import os
        from datetime import datetime

        # Cr√©ation du dossier de cache
        os.makedirs("model_cache", exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for model_name, model_data in models_data.items():
            try:
                filename = f"model_cache/model_{model_name}_{timestamp}.joblib"

                # Donn√©es √† sauvegarder
                save_data = {
                    'model': model_data.get('best_model') or model_data.get('model'),
                    'params': model_data.get('best_params', {}),
                    'metrics': {
                        'accuracy': model_data.get('test_accuracy', 0),
                        'auc': model_data.get('test_auc', 0)
                    },
                    'timestamp': timestamp
                }

                joblib.dump(save_data, filename)
                st.success(f"‚úÖ {model_name} sauvegard√©")

            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur sauvegarde {model_name}: {str(e)}")
                continue

    except ImportError:
        st.warning("‚ö†Ô∏è Joblib non disponible, sauvegarde d√©sactiv√©e")

        # Alternative : sauvegarde des param√®tres seulement
        try:
            import json

            params_data = {}
            for name, data in models_data.items():
                params_data[name] = {
                    'params': data.get('best_params', {}),
                    'metrics': {
                        'accuracy': float(data.get('test_accuracy', 0)),
                        'auc': float(data.get('test_auc', 0))
                    }
                }

            with open(f"model_cache/params_{timestamp}.json", 'w') as f:
                json.dump(params_data, f, indent=2)

            st.info("üíæ Param√®tres sauvegard√©s en JSON")

        except Exception as e:
            st.error(f"‚ùå Erreur sauvegarde alternative : {str(e)}")

def get_saved_models_list():
    """Retourne la liste des mod√®les sauvegard√©s"""
    try:
        import os

        # Cr√©ation du dossier s'il n'existe pas
        if not os.path.exists("model_cache"):
            os.makedirs("model_cache", exist_ok=True)
            return []

        # R√©cup√©ration des fichiers .joblib
        files = [f for f in os.listdir("model_cache") if f.endswith('.joblib')]

        # Tri par date de modification (plus r√©cents en premier)
        files_with_time = []
        for f in files:
            file_path = os.path.join("model_cache", f)
            mod_time = os.path.getmtime(file_path)
            files_with_time.append((f, mod_time))

        # Tri par temps de modification d√©croissant
        files_with_time.sort(key=lambda x: x[1], reverse=True)

        return [f[0] for f in files_with_time]

    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des mod√®les : {str(e)}")
        return []

def create_model_instance_corrected(model_name):
    """Cr√©e une nouvelle instance du mod√®le bas√©e sur son nom - VERSION S√âCURIS√âE"""
    try:
        from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.svm import SVC
        from sklearn.neighbors import KNeighborsClassifier

        # Mapping corrig√© et √©tendu
        model_mapping = {
            'RandomForestClassifier': RandomForestClassifier(random_state=42),
            'RandomForest': RandomForestClassifier(random_state=42),
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'LogReg_L1': LogisticRegression(penalty='l1', solver='liblinear', random_state=42),
            'LogReg_L2': LogisticRegression(penalty='l2', random_state=42, max_iter=1000),
            'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42),
            'GradientBoosting': GradientBoostingClassifier(random_state=42),
            'SVC': SVC(probability=True, random_state=42),
            'KNeighborsClassifier': KNeighborsClassifier()
        }

        # Recherche exacte
        if model_name in model_mapping:
            return model_mapping[model_name]

        # Recherche par contenu
        for key, model in model_mapping.items():
            if key in model_name or model_name in key:
                return model

        # Fallback s√ªr
        print(f"‚ö†Ô∏è Mod√®le {model_name} non reconnu, utilisation de LogisticRegression par d√©faut")
        return LogisticRegression(random_state=42, max_iter=1000)

    except Exception as e:
        print(f"‚ùå Erreur cr√©ation mod√®le {model_name}: {str(e)}")
        return LogisticRegression(random_state=42, max_iter=1000)  # Fallback tr√®s s√ªr

def load_saved_model(filename):
    """Charge un mod√®le sauvegard√© avec Joblib"""
    try:
        import joblib
        import os

        # V√©rification de l'existence du fichier
        full_path = os.path.join("model_cache", filename)
        if not os.path.exists(full_path):
            st.error(f"‚ùå Fichier non trouv√© : {filename}")
            return None

        # Chargement du mod√®le avec Joblib
        loaded_data = joblib.load(full_path) [17]

        # Validation des donn√©es charg√©es
        if not isinstance(loaded_data, dict):
            st.warning("‚ö†Ô∏è Format de donn√©es inattendu")
            return loaded_data

        # V√©rification des cl√©s essentielles
        required_keys = ['model', 'timestamp']
        missing_keys = [key for key in required_keys if key not in loaded_data]

        if missing_keys:
            st.warning(f"‚ö†Ô∏è Cl√©s manquantes dans le mod√®le : {missing_keys}")

        return loaded_data

    except ImportError:
        st.error("‚ùå Joblib non disponible. Installez avec : pip install joblib")
        return None
    except Exception as e:
        st.error(f"‚ùå Erreur de chargement : {str(e)}")
        return None

def get_top_models_corrected(models_results, n=3):
    """Version corrig√©e qui r√©cup√®re les instances de mod√®les correctement"""
    try:
        # Conversion s√©curis√©e en DataFrame
        if isinstance(models_results, dict):
            df_results = pd.DataFrame(models_results).T
        else:
            df_results = models_results.copy()

        # V√©rifier les colonnes disponibles
        available_columns = df_results.columns.tolist()

        # Trouver la colonne AUC appropri√©e
        auc_column = None
        for col_name in ['ROC AUC', 'ROC_AUC', 'roc_auc', 'AUC', 'auc']:
            if col_name in available_columns:
                auc_column = col_name
                break

        if auc_column is None:
            auc_column = 'Accuracy'

        # Tri par performance
        df_sorted = df_results.sort_values(auc_column, ascending=False)

        # S√©lection des n meilleurs mod√®les avec cr√©ation d'instances
        top_models = {}

        for i, (model_name, row) in enumerate(df_sorted.head(n).iterrows()):
            # CORRECTION: Toujours cr√©er une nouvelle instance du mod√®le
            model_instance = create_model_instance_corrected(model_name)

            top_models[model_name] = {
                'auc': float(row.get(auc_column, 0)),
                'accuracy': float(row.get('Accuracy', 0)),
                'model': model_instance  # Instance garantie
            }

        return top_models

    except Exception as e:
        print(f"‚ùå Erreur dans get_top_models : {str(e)}")
        return {}

def display_optimization_results(optimized_results):
    """Affiche les r√©sultats d'optimisation des mod√®les"""
    st.markdown("### üèÜ R√©sultats de l'optimisation")

    # Tableau des r√©sultats
    results_data = []
    for model_name, results in optimized_results.items():
        results_data.append({
            'Mod√®le': model_name,
            'Meilleurs param√®tres': str(results.get('best_params', 'N/A')),
            'Score CV': f"{results.get('best_score', 0):.4f}",
            'Accuracy Test': f"{results.get('test_accuracy', 0):.4f}",
            'AUC Test': f"{results.get('test_auc', 0):.4f}"
        })

    if results_data:
        results_df = pd.DataFrame(results_data)
        st.dataframe(results_df, use_container_width=True)
    else:
        st.warning("Aucun r√©sultat d'optimisation disponible")

def simple_ml_analysis(X_train, X_test, y_train, y_test):
    """Version simplifi√©e de l'analyse ML"""
    try:
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import accuracy_score, classification_report

        models = {
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
        }

        results = {}

        for name, model in models.items():
            # Entra√Ænement
            model.fit(X_train, y_train)

            # Pr√©diction
            y_pred = model.predict(X_test)

            # M√©triques
            accuracy = accuracy_score(y_test, y_pred)
            report = classification_report(y_test, y_pred, output_dict=True)

            results[name] = {
                'accuracy': accuracy,
                'precision': report['weighted avg']['precision'],
                'recall': report['weighted avg']['recall'],
                'f1': report['weighted avg']['f1-score'],
                'model': model
            }

        return results

    except Exception as e:
        st.error(f"‚ùå Erreur analyse simplifi√©e : {str(e)}")
        return None

def display_simple_results(results):
    """Affiche les r√©sultats de l'analyse simplifi√©e"""
    st.markdown("### üìä R√©sultats de l'Analyse Simplifi√©e")

    for name, metrics in results.items():
        if name != 'model':
            st.markdown(f"**{name}:**")
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Accuracy", f"{metrics['accuracy']:.3f}")
            with col2:
                st.metric("Precision", f"{metrics['precision']:.3f}")
            with col3:
                st.metric("Recall", f"{metrics['recall']:.3f}")
            with col4:
                st.metric("F1-Score", f"{metrics['f1']:.3f}")

            st.markdown("---")

def run_manual_40_models_fixed(X_train, X_test, y_train, y_test):
    """Version corrig√©e qui stocke les instances de mod√®les"""
    try:
        from sklearn.ensemble import (
            RandomForestClassifier, GradientBoostingClassifier,
            ExtraTreesClassifier, AdaBoostClassifier
        )
        from sklearn.linear_model import LogisticRegression
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
        import time

        # Dictionnaire des mod√®les avec instances
        models_dict = {
            'RandomForestClassifier': RandomForestClassifier(n_estimators=100, random_state=42),
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'GradientBoostingClassifier': GradientBoostingClassifier(random_state=42),
            'LogReg_L1': LogisticRegression(penalty='l1', solver='liblinear', random_state=42),
            'LogReg_L2': LogisticRegression(penalty='l2', random_state=42, max_iter=1000)
        }

        results = {}
        model_instances = {}  # Stockage s√©par√© des instances

        for name, model in models_dict.items():
            try:
                start_time = time.time()

                # Entra√Ænement
                model.fit(X_train, y_train)

                # Pr√©dictions
                y_pred = model.predict(X_test)

                # Probabilit√©s si disponibles
                if hasattr(model, 'predict_proba'):
                    try:
                        y_proba = model.predict_proba(X_test)[:, 1]
                        auc = roc_auc_score(y_test, y_proba)
                    except:
                        auc = 0.5
                else:
                    auc = 0.5

                # Calcul des m√©triques
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, zero_division=0)
                recall = recall_score(y_test, y_pred, zero_division=0)
                f1 = f1_score(y_test, y_pred, zero_division=0)

                time_taken = time.time() - start_time

                # Stockage des r√©sultats AVEC l'instance du mod√®le
                results[name] = {
                    'Accuracy': float(accuracy),
                    'Balanced Accuracy': float(accuracy),
                    'ROC AUC': float(auc),
                    'F1 Score': float(f1),
                    'Time Taken': float(time_taken),
                    'model_instance': model  # CRUCIAL : stocker l'instance
                }

                # Stockage s√©par√© pour l'optimisation
                model_instances[name] = model

            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur avec {name}: {str(e)}")
                continue

        if results:
            # Stocker les instances dans session state pour l'optimisation
            st.session_state.model_instances = model_instances

            # Cr√©er le DataFrame sans les instances pour l'affichage
            display_results = {}
            for name, data in results.items():
                display_data = {k: v for k, v in data.items() if k != 'model_instance'}
                display_results[name] = display_data

            results_df = pd.DataFrame(display_results).T
            results_df_sorted = results_df.sort_values(['ROC AUC', 'Accuracy'], ascending=False)
            return results_df_sorted
        else:
            st.error("‚ùå Aucun mod√®le entra√Æn√© avec succ√®s")
            return None

    except Exception as e:
        st.error(f"‚ùå Erreur globale : {str(e)}")
        return None


def optimize_selected_models(best_models, X_train, X_test, y_train, y_test):
    """Version corrig√©e de l'optimisation des hyperparam√®tres"""

    try:
        from sklearn.model_selection import GridSearchCV
        from sklearn.metrics import accuracy_score, roc_auc_score

        # V√©rification pr√©alable des mod√®les
        if not best_models:
            st.error("‚ùå Aucun mod√®le fourni pour l'optimisation")
            return None

        st.info(f"üîß D√©but de l'optimisation de {len(best_models)} mod√®les...")

        # Grilles de param√®tres simplifi√©es pour √©viter les timeouts
        param_grids = {
            'RandomForestClassifier': {
                'n_estimators': [50, 100],
                'max_depth': [5, 10, None],
                'min_samples_split': [2, 5]
            },
            'LogisticRegression': {
                'C': [0.1, 1, 10],
                'solver': ['lbfgs', 'liblinear'],
                'max_iter': [1000]
            },
            'LogReg_L1': {
                'C': [0.1, 1, 10],
                'solver': ['liblinear'],
                'max_iter': [1000]
            },
            'LogReg_L2': {
                'C': [0.1, 1, 10],
                'solver': ['lbfgs'],
                'max_iter': [1000]
            },
            'GradientBoostingClassifier': {
                'n_estimators': [50, 100],
                'learning_rate': [0.01, 0.1],
                'max_depth': [3, 5]
            }
        }

        optimized_results = {}

        for model_name, model_data in best_models.items():
            try:
                st.info(f"üîß Optimisation de {model_name}...")

                # V√©rification de la pr√©sence du mod√®le
                if 'model' not in model_data or model_data['model'] is None:
                    st.warning(f"‚ö†Ô∏è Instance de mod√®le manquante pour {model_name}")
                    # Cr√©er une nouvelle instance
                    base_model = create_model_instance_corrected(model_name)
                else:
                    # Utiliser l'instance existante mais cr√©er une nouvelle pour GridSearch
                    base_model = create_model_instance_corrected(model_name)

                # D√©terminer la grille de param√®tres
                grid_key = model_name
                if grid_key not in param_grids:
                    # Recherche par similarit√© de nom
                    for key in param_grids.keys():
                        if key in model_name or model_name in key:
                            grid_key = key
                            break
                    else:
                        # Fallback par d√©faut
                        grid_key = 'RandomForestClassifier'
                        base_model = RandomForestClassifier(random_state=42)

                param_grid = param_grids[grid_key]

                # Configuration GridSearchCV
                grid_search = GridSearchCV(
                    estimator=base_model,
                    param_grid=param_grid,
                    cv=3,  # R√©duction pour √©viter les timeouts
                    scoring='roc_auc',
                    n_jobs=1,  # R√©duction de la charge
                    verbose=0,
                    error_score='raise'
                )

                # Entra√Ænement avec gestion d'erreur
                try:
                    grid_search.fit(X_train, y_train)
                except Exception as fit_error:
                    st.warning(f"‚ö†Ô∏è Erreur GridSearchCV pour {model_name}: {str(fit_error)}")
                    continue

                # V√©rification que GridSearch a fonctionn√©
                if not hasattr(grid_search, 'best_estimator_') or grid_search.best_estimator_ is None:
                    st.warning(f"‚ö†Ô∏è GridSearchCV n'a pas produit de meilleur mod√®le pour {model_name}")
                    continue

                # √âvaluation sur test set
                y_pred = grid_search.predict(X_test)

                # Calcul AUC avec gestion d'erreur
                try:
                    y_proba = grid_search.predict_proba(X_test)[:, 1]
                    test_auc = roc_auc_score(y_test, y_proba)
                except:
                    test_auc = 0.5

                test_accuracy = accuracy_score(y_test, y_pred)

                # Stockage des r√©sultats
                optimized_results[model_name] = {
                    'best_model': grid_search.best_estimator_,
                    'best_params': grid_search.best_params_,
                    'best_cv_score': grid_search.best_score_,
                    'test_accuracy': test_accuracy,
                    'test_auc': test_auc,
                    'n_candidates': len(grid_search.cv_results_['params'])
                }

                st.success(f"‚úÖ {model_name} optimis√© - AUC: {test_auc:.3f}")

            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur optimisation {model_name}: {str(e)}")
                continue

        if optimized_results:
            st.success(f"‚úÖ Optimisation termin√©e pour {len(optimized_results)} mod√®les")
            return optimized_results
        else:
            st.error("‚ùå Aucune optimisation n'a abouti")
            return None

    except ImportError as e:
        st.error(f"‚ùå Erreur d'import : {e}")
        return None

    except Exception as e:
        st.error(f"‚ùå Erreur g√©n√©rale d'optimisation : {str(e)}")
        return None


def display_optimization_results(optimized_results):
    """Affiche les r√©sultats d'optimisation de mani√®re d√©taill√©e"""

    if not optimized_results:
        st.warning("‚ö†Ô∏è Aucun r√©sultat d'optimisation disponible")
        return

    st.markdown("### üèÜ R√©sultats de l'Optimisation")

    # Tableau r√©capitulatif
    results_data = []
    for model_name, results in optimized_results.items():
        results_data.append({
            'Mod√®le': model_name,
            'AUC Test': f"{results.get('test_auc', 0):.4f}",
            'Accuracy Test': f"{results.get('test_accuracy', 0):.4f}",
            'CV Score': f"{results.get('best_cv_score', 0):.4f}",
            'Nb Configs': results.get('n_candidates', 'N/A'),
            'Meilleurs Param√®tres': str(results.get('best_params', {}))[:100] + "..."
        })

    if results_data:
        results_df = pd.DataFrame(results_data)
        st.dataframe(results_df, use_container_width=True)

        # Identification du meilleur mod√®le
        best_model = max(optimized_results.items(), key=lambda x: x[1].get('test_auc', 0))

        st.markdown(f"""
        <div style="background: linear-gradient(135deg, #4caf50, #8bc34a);
                   padding: 20px; border-radius: 10px; margin: 20px 0; text-align: center;">
            <h3 style="color: white; margin: 0;">ü•á MEILLEUR MOD√àLE</h3>
            <h2 style="color: white; margin: 10px 0;">{best_model[0]}</h2>
            <p style="color: white; margin: 0; font-size: 1.2rem;">
                AUC: {best_model[1].get('test_auc', 0):.4f} |
                Accuracy: {best_model[1].get('test_accuracy', 0):.4f}
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Param√®tres optimaux du meilleur mod√®le
        st.markdown("### ‚öôÔ∏è Param√®tres Optimaux du Meilleur Mod√®le")
        best_params = best_model[1].get('best_params', {})

        params_cols = st.columns(min(len(best_params), 4))
        for i, (param, value) in enumerate(best_params.items()):
            with params_cols[i % 4]:
                st.metric(param, str(value))



def show_enhanced_ml_analysis():
    """Version corrig√©e avec gestion compl√®te du session state"""

    # En-t√™te
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;">
            üß† Analyse ML Avanc√©e - CORRIG√âE
        </h1>
    </div>
    """, unsafe_allow_html=True)

    # Chargement du dataset
    df = load_enhanced_dataset()
    if df is None or len(df) == 0:
        st.error("Impossible de charger le dataset")
        return

    # Onglets ML corrig√©s
    ml_tabs = st.tabs([
        "üî¨ Comparaison 40+ Mod√®les",
        "üèÜ Top 3 Optimis√©s",
        "üìä Visualisations",
        "üíæ Sauvegarde",
        "üìà M√©triques"
    ])

    with ml_tabs[0]:
        st.subheader("üî¨ Comparaison de 40+ Mod√®les ML")

        # Affichage de l'√©tat des variables
        if 'models_results' in st.session_state:
            st.success("‚úÖ R√©sultats de mod√®les disponibles")
        if all(key in st.session_state for key in ['X_train', 'X_test', 'y_train', 'y_test']):
            st.success("‚úÖ Donn√©es d'entra√Ænement disponibles")

        if st.button("üöÄ Lancer la Comparaison Massive", type="primary"):
            with st.spinner("Entra√Ænement en cours..."):
                try:
                    # Pr√©paration des donn√©es AVANT tout autre traitement
                    X_train, X_test, y_train, y_test = prepare_ml_data_safe(df)

                    # V√©rification que les donn√©es sont valides
                    if X_train is None or len(X_train) == 0:
                        st.error("‚ùå Erreur dans la pr√©paration des donn√©es")
                        return

                    # Stockage imm√©diat dans session state
                    st.session_state.X_train = X_train
                    st.session_state.X_test = X_test
                    st.session_state.y_train = y_train
                    st.session_state.y_test = y_test

                    st.info(f"‚úÖ Donn√©es pr√©par√©es : {len(X_train)} √©chantillons d'entra√Ænement")

                    # Lancement de l'entra√Ænement des mod√®les
                    models_results = run_manual_40_models_fixed(X_train, X_test, y_train, y_test)

                    if models_results is not None and len(models_results) > 0:
                        st.session_state.models_results = models_results
                        st.success(f"‚úÖ {len(models_results)} mod√®les compar√©s avec succ√®s!")
                        display_manual_results(models_results)
                    else:
                        st.error("‚ùå Aucun mod√®le n'a pu √™tre entra√Æn√©")

                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'entra√Ænement : {str(e)}")
                    # Nettoyage en cas d'erreur
                    for key in ['X_train', 'X_test', 'y_train', 'y_test', 'models_results']:
                        if key in st.session_state:
                            del st.session_state[key]

    with ml_tabs[1]:
        st.subheader("üèÜ Optimisation des Meilleurs Mod√®les")

        # V√©rification pr√©alable compl√®te
        models_available = 'models_results' in st.session_state and st.session_state.models_results is not None
        data_available = all(key in st.session_state for key in ['X_train', 'X_test', 'y_train', 'y_test'])
        instances_available = 'model_instances' in st.session_state

        if not models_available:
            st.warning("‚ö†Ô∏è Aucun r√©sultat de mod√®le disponible")
            st.info("üëÜ Lancez d'abord la comparaison dans l'onglet pr√©c√©dent")
            return

        if not data_available:
            st.error("‚ùå Donn√©es d'entra√Ænement manquantes")
            st.info("üîÑ Relancez la comparaison des mod√®les")
            return

        if not instances_available:
            st.warning("‚ö†Ô∏è Instances de mod√®les manquantes, recr√©ation en cours...")

        try:
            models_results = st.session_state.models_results

            st.markdown("### üéØ S√©lection des 3 meilleurs mod√®les")
            st.info(f"üìä {len(models_results)} mod√®les disponibles")

            # S√©lection des meilleurs mod√®les avec gestion d'erreur
            best_models = get_top_models_corrected(models_results, n=3)

            if not best_models:
                st.error("‚ùå Impossible de s√©lectionner les meilleurs mod√®les")
                return

            # Affichage des mod√®les s√©lectionn√©s
            st.markdown("**Mod√®les s√©lectionn√©s pour l'optimisation :**")
            for name, metrics in best_models.items():
                has_model = 'model' in metrics and metrics['model'] is not None
                model_status = "‚úÖ" if has_model else "‚ùå"
                st.write(f"‚Ä¢ **{name}** {model_status} - AUC: {metrics['auc']:.3f}, Accuracy: {metrics['accuracy']:.3f}")

            if st.button("üîß Optimiser le Top 3", type="primary"):
                with st.spinner("üîÑ Optimisation en cours..."):
                    try:
                        # R√©cup√©ration s√©curis√©e des donn√©es
                        X_train = st.session_state.X_train
                        X_test = st.session_state.X_test
                        y_train = st.session_state.y_train
                        y_test = st.session_state.y_test

                        # V√©rification finale
                        if any(var is None for var in [X_train, X_test, y_train, y_test]):
                            st.error("‚ùå Variables d'entra√Ænement corrompues")
                            return

                        # Lancement de l'optimisation corrig√©e
                        optimized_results = optimize_selected_models(
                            best_models, X_train, X_test, y_train, y_test
                        )

                        if optimized_results and len(optimized_results) > 0:
                            st.session_state.optimized_models = optimized_results
                            st.success(f"‚úÖ Optimisation r√©ussie ! {len(optimized_results)} mod√®les optimis√©s")
                            display_optimization_results(optimized_results)
                        else:
                            st.error("‚ùå L'optimisation n'a produit aucun r√©sultat")

                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de l'optimisation : {str(e)}")
                        st.info("üí° Essayez de relancer la comparaison des mod√®les")

        except Exception as e:
            st.error(f"‚ùå Erreur dans la s√©lection des mod√®les : {str(e)}")

    # Autres onglets avec v√©rifications similaires
    with ml_tabs[2]:
        st.subheader("üìä Visualisations Avanc√©es")

        if 'optimized_models' in st.session_state and st.session_state.optimized_models:
            create_advanced_visualizations(st.session_state.optimized_models)
        else:
            st.warning("‚ö†Ô∏è Optimisez d'abord les mod√®les pour voir les visualisations")

    with ml_tabs[3]:
        st.subheader("üíæ Sauvegarde des Mod√®les")

        if 'optimized_models' in st.session_state and st.session_state.optimized_models:
            if st.button("üíæ Sauvegarder tous les mod√®les"):
                save_all_models(st.session_state.optimized_models)
        else:
            st.info("‚ÑπÔ∏è Aucun mod√®le optimis√© √† sauvegarder")

    with ml_tabs[4]:
        st.subheader("üìà M√©triques D√©taill√©es")

        if 'optimized_models' in st.session_state and st.session_state.optimized_models:
            display_detailed_metrics(st.session_state.optimized_models)
        else:
            st.info("‚ÑπÔ∏è Optimisez d'abord les mod√®les pour voir les m√©triques")


def show_enhanced_ai_prediction():
    if not check_rgpd_consent():
        return
    """Interface de pr√©diction IA enrichie avec test ASRS complet"""
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            ü§ñ Test ASRS Complet & Pr√©diction IA
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            √âvaluation officielle ASRS v1.1 de l'OMS avec analyse par intelligence artificielle
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Onglets pour la pr√©diction
    pred_tabs = st.tabs([
        "üìù Test ASRS Officiel",
        "ü§ñ Analyse IA",
        "üìä R√©sultats D√©taill√©s",
        "üìà KPIs Avanc√©s",
        "üí° Recommandations"
    ])

    with pred_tabs[0]:
        st.markdown("""
        <style>
        .question-container {
            background: linear-gradient(135deg, #fff3e0, #ffcc02);
            border-radius: 12px;
            padding: 25px;
            margin: 20px 0;
            border-left: 4px solid #ff5722;
            box-shadow: 0 4px 12px rgba(255,87,34,0.1);
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .question-container:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(255,87,34,0.15);
        }

        .question-number {
            background: linear-gradient(135deg, #ff5722, #ff9800);
            color: white;
            width: 35px;
            height: 35px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 1.1rem;
            margin-bottom: 15px;
        }

        .question-text {
            color: #d84315;
            font-size: 1.1rem;
            line-height: 1.6;
            margin-bottom: 20px;
            font-weight: 500;
        }

        .response-options {
            display: flex;
            justify-content: space-between;
            gap: 10px;
            flex-wrap: wrap;
        }

        .response-option {
            flex: 1;
            min-width: 120px;
            text-align: center;
        }

        /* Style pour les radio buttons */
        .stRadio > div {
            flex-direction: row !important;
            justify-content: space-between !important;
            gap: 15px !important;
        }

        .stRadio label {
            background: white;
            border: 2px solid #ffcc02;
            border-radius: 8px;
            padding: 8px 12px;
            margin: 0 !important;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.9rem;
            text-align: center;
            min-width: 100px;
        }

        .stRadio label:hover {
            background: #fff3e0;
            border-color: #ff9800;
            transform: translateY(-1px);
        }

        .stRadio input[type="radio"]:checked + div {
            background: linear-gradient(135deg, #ff5722, #ff9800) !important;
            color: white !important;
            border-color: #ff5722 !important;
        }
        </style>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                    padding: 30px 20px; border-radius: 15px; margin-bottom: 30px; text-align: center;">
            <h1 style="color: white; font-size: 2.5rem; margin-bottom: 10px; font-weight: 600;">
                üß† Questionnaire ASRS v1.1
            </h1>
            <p style="color: rgba(255,255,255,0.95); font-size: 1.2rem; margin: 0;">
                Test de d√©pistage du TDAH chez l'adulte - Organisation Mondiale de la Sant√©
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Instructions
        st.markdown("""
        <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; margin-bottom: 25px; border-left: 4px solid #ff9800;">
            <h3 style="color: #ef6c00; margin-top: 0;">üìã Instructions</h3>
            <p style="color: #f57c00; line-height: 1.6; margin-bottom: 10px;">
                <strong>Pour chaque affirmation, indiquez √† quelle fr√©quence vous avez v√©cu cette situation au cours des 6 derniers mois :</strong>
            </p>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 10px; margin-top: 15px;">
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center; border-left: 3px solid #4caf50;">
                    <strong style="color: #2e7d32;">Jamais</strong><br><small>0 point</small>
                </div>
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center; border-left: 3px solid #8bc34a;">
                    <strong style="color: #558b2f;">Rarement</strong><br><small>1 point</small>
                </div>
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center; border-left: 3px solid #ffeb3b;">
                    <strong style="color: #f57f17;">Parfois</strong><br><small>2 points</small>
                </div>
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center; border-left: 3px solid #ff9800;">
                    <strong style="color: #ef6c00;">Souvent</strong><br><small>3 points</small>
                </div>
                <div style="background: white; padding: 10px; border-radius: 6px; text-align: center; border-left: 3px solid #f44336;">
                    <strong style="color: #c62828;">Tr√®s souvent</strong><br><small>4 points</small>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)

        # Questions ASRS transform√©es en affirmations
        asrs_statements = [
            "Je remarque souvent de petits bruits que les autres ne remarquent pas.",
            "Je me concentre g√©n√©ralement davantage sur l'ensemble que sur les petits d√©tails.",
            "J'ai des difficult√©s √† terminer les d√©tails finaux d'un projet, une fois que les parties difficiles ont √©t√© faites.",
            "J'ai des difficult√©s √† organiser les t√¢ches lorsque je dois faire quelque chose qui demande de l'organisation.",
            "J'ai des probl√®mes pour me rappeler des rendez-vous ou des obligations.",
            "J'√©vite ou retarde de commencer des t√¢ches qui demandent beaucoup de r√©flexion.",
            "Je bouge ou me tortille avec mes mains ou mes pieds quand je dois rester assis longtemps.",
            "Je me sens excessivement actif et oblig√© de faire des choses, comme si j'√©tais men√© par un moteur.",
            "Je fais des erreurs d'inattention quand je travaille sur un projet ennuyeux ou difficile.",
            "J'ai des difficult√©s √† maintenir mon attention quand je fais un travail ennuyeux ou r√©p√©titif.",
            "J'ai des difficult√©s √† me concentrer sur ce que les gens me disent, m√™me quand ils s'adressent directement √† moi.",
            "J'√©gare ou ai des difficult√©s √† retrouver des choses √† la maison ou au travail.",
            "Je suis distrait par l'activit√© ou le bruit autour de moi.",
            "Je quitte mon si√®ge dans des r√©unions ou d'autres situations o√π je devrais rester assis.",
            "Je me sens agit√© ou nerveux.",
            "J'ai des difficult√©s √† me d√©tendre quand j'ai du temps libre.",
            "Je me retrouve √† trop parler dans des situations sociales.",
            "Quand je suis en conversation, je finis les phrases des personnes √† qui je parle, avant qu'elles puissent les finir elles-m√™mes.",
            "J'ai des difficult√©s √† attendre mon tour dans des situations o√π chacun doit attendre son tour.",
            "J'interromps les autres quand ils sont occup√©s."
        ]

        # Options de r√©ponse
        response_options = ["Jamais", "Rarement", "Parfois", "Souvent", "Tr√®s souvent"]

        # Initialisation des r√©ponses
        if 'asrs_responses_aq10' not in st.session_state:
            st.session_state.asrs_responses_aq10 = {}

        # Formulaire principal
        with st.form("asrs_aq10_format", clear_on_submit=False):

            # Partie A - Questions principales (1-6)
            st.markdown("""
            <div style="background: linear-gradient(135deg, #ff5722, #ff9800); padding: 20px; border-radius: 12px; margin: 25px 0;">
                <h2 style="color: white; margin: 0; text-align: center;">
                    üéØ Partie A - Questions de d√©pistage principal
                </h2>
                <p style="color: rgba(255,255,255,0.9); text-align: center; margin: 10px 0 0 0;">
                    Ces 6 questions sont les plus pr√©dictives pour le d√©pistage du TDAH
                </p>
            </div>
            """, unsafe_allow_html=True)

            for i in range(6):
                st.markdown(f"""
                <div class="question-container">
                    <div class="question-number">{i+1}</div>
                    <div class="question-text">{asrs_statements[i+2]}</div>  <!-- Commence √† l'index 2 pour √©viter les questions autism -->
                </div>
                """, unsafe_allow_html=True)

                response = st.radio(
                    f"Question {i+1}",
                    response_options,
                    key=f"asrs_part_a_q{i+1}",
                    horizontal=True,
                    label_visibility="collapsed"
                )
                st.session_state.asrs_responses_aq10[f'part_a_q{i+1}'] = response

            # Partie B - Questions compl√©mentaires (7-18)
            st.markdown("""
            <div style="background: linear-gradient(135deg, #ff9800, #ffcc02); padding: 20px; border-radius: 12px; margin: 25px 0;">
                <h2 style="color: white; margin: 0; text-align: center;">
                    üìù Partie B - Questions compl√©mentaires
                </h2>
                <p style="color: rgba(255,255,255,0.9); text-align: center; margin: 10px 0 0 0;">
                    Ces 12 questions fournissent des informations suppl√©mentaires pour l'√©valuation
                </p>
            </div>
            """, unsafe_allow_html=True)

            for i in range(12):
                question_num = i + 7
                statement_index = i + 8  # Ajustement pour les bonnes questions

                st.markdown(f"""
                <div class="question-container">
                    <div class="question-number">{question_num}</div>
                    <div class="question-text">{asrs_statements[statement_index]}</div>
                </div>
                """, unsafe_allow_html=True)

                response = st.radio(
                    f"Question {question_num}",
                    response_options,
                    key=f"asrs_part_b_q{question_num}",
                    horizontal=True,
                    label_visibility="collapsed"
                )
                st.session_state.asrs_responses_aq10[f'part_b_q{question_num}'] = response

            # Informations d√©mographiques
            st.markdown("""
            <div style="background: linear-gradient(135deg, #ffcc02, #fff3e0); padding: 20px; border-radius: 12px; margin: 25px 0;">
                <h2 style="color: #d84315; margin: 0; text-align: center;">
                    üë§ Informations compl√©mentaires
                </h2>
            </div>
            """, unsafe_allow_html=True)

            col1, col2, col3 = st.columns(3)

            with col1:
                age = st.number_input("√Çge", min_value=18, max_value=80, value=30)
                gender = st.selectbox("Genre", ["Masculin", "F√©minin", "Autre"])

            with col2:
                education = st.selectbox("Niveau d'√©ducation",
                                       ["Bac", "Bac+2", "Bac+3", "Bac+5", "Doctorat"])
                job_status = st.selectbox("Statut professionnel",
                                        ["CDI", "CDD", "Freelance", "√âtudiant", "Ch√¥meur"])

            with col3:
                quality_of_life = st.slider("Qualit√© de vie (1-10)", 1, 10, 5)
                stress_level = st.slider("Niveau de stress (1-5)", 1, 5, 3)

            # Bouton de soumission
            submitted = st.form_submit_button(
                "üî¨ Analyser les r√©sultats",
                use_container_width=True,
                type="primary"
            )


            if submitted:
                # Calcul des scores ASRS
                part_a_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in range(1, 7)])
                part_b_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in range(7, 19)])
                total_score = part_a_score + part_b_score

                # Score d'inattention (questions 1-9 selon DSM-5)
                inattention_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in [1, 2, 3, 4, 7, 8, 9]])

                # Score d'hyperactivit√©-impulsivit√© (questions 5, 6, 10-18)
                hyperactivity_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in [5, 6] + list(range(10, 19))])

                # Stockage des r√©sultats
                st.session_state.asrs_results = {
                    'responses': st.session_state.asrs_responses.copy(),
                    'scores': {
                        'part_a': part_a_score,
                        'part_b': part_b_score,
                        'total': total_score,
                        'inattention': inattention_score,
                        'hyperactivity': hyperactivity_score
                    },
                    'demographics': {
                        'age': age,
                        'gender': gender,
                        'education': education,
                        'job_status': job_status,
                        'quality_of_life': quality_of_life,
                        'stress_level': stress_level
                    }
                }

                st.success("‚úÖ Test ASRS compl√©t√© ! Consultez les onglets suivants pour l'analyse IA.")

    with pred_tabs[1]:
        if 'asrs_results' in st.session_state:
            st.subheader("ü§ñ Analyse par Intelligence Artificielle")

            results = st.session_state.asrs_results

            # Analyse des scores selon les crit√®res officiels
            st.markdown("### üìä Analyse selon les crit√®res ASRS officiels")

            part_a_score = results['scores']['part_a']

            # Crit√®res ASRS partie A (seuil de 14 points sur 24)
            asrs_positive = part_a_score >= 14

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Score Partie A", f"{part_a_score}/24")
            with col2:
                st.metric("Score Total", f"{results['scores']['total']}/72")
            with col3:
                risk_level = "√âLEV√â" if asrs_positive else "FAIBLE"
                color = "üî¥" if asrs_positive else "üü¢"
                st.metric("Risque TDAH", f"{color} {risk_level}")

            # Simulation d'analyse IA avanc√©e
            st.markdown("### üß† Analyse IA Multicrit√®res")

            # Calcul du score de risque IA (simulation r√©aliste)
            ai_risk_factors = 0

            # Facteur 1: Score ASRS partie A
            if part_a_score >= 16:
                ai_risk_factors += 0.4
            elif part_a_score >= 14:
                ai_risk_factors += 0.3
            elif part_a_score >= 10:
                ai_risk_factors += 0.2

            # Facteur 2: Score total
            total_score = results['scores']['total']
            if total_score >= 45:
                ai_risk_factors += 0.25
            elif total_score >= 35:
                ai_risk_factors += 0.15

            # Facteur 3: D√©s√©quilibre inattention/hyperactivit√©
            inatt_score = results['scores']['inattention']
            hyper_score = results['scores']['hyperactivity']
            if abs(inatt_score - hyper_score) > 10:
                ai_risk_factors += 0.1

            # Facteur 4: D√©mographie
            age = results['demographics']['age']
            if age < 25:
                ai_risk_factors += 0.05

            # Facteur 5: Qualit√© de vie et stress
            qol = results['demographics']['quality_of_life']
            stress = results['demographics']['stress_level']
            if qol < 5 and stress > 3:
                ai_risk_factors += 0.1

            # Facteur 6: Pattern de r√©ponses
            high_responses = sum([1 for score in results['responses'].values() if score >= 3])
            if high_responses >= 8:
                ai_risk_factors += 0.1

            ai_probability = min(ai_risk_factors, 0.95)

            # Affichage du r√©sultat IA
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Probabilit√© IA TDAH", f"{ai_probability:.1%}")
            with col2:
                confidence = "Tr√®s √©lev√©e" if ai_probability > 0.8 else "√âlev√©e" if ai_probability > 0.6 else "Mod√©r√©e" if ai_probability > 0.4 else "Faible"
                st.metric("Confiance", confidence)
            with col3:
                recommendation = "Urgente" if ai_probability > 0.8 else "Recommand√©e" if ai_probability > 0.6 else "Conseill√©e" if ai_probability > 0.4 else "Surveillance"
                st.metric("Consultation", recommendation)
            with col4:
                risk_category = "Tr√®s √©lev√©" if ai_probability > 0.8 else "√âlev√©" if ai_probability > 0.6 else "Mod√©r√©" if ai_probability > 0.4 else "Faible"
                st.metric("Cat√©gorie risque", risk_category)

            # Gauge de probabilit√©
            fig_gauge = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = ai_probability * 100,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Probabilit√© TDAH (%)"},
                delta = {'reference': 50},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "#ff5722"},
                    'steps': [
                        {'range': [0, 40], 'color': "#c8e6c9"},
                        {'range': [40, 60], 'color': "#fff3e0"},
                        {'range': [60, 80], 'color': "#ffcc02"},
                        {'range': [80, 100], 'color': "#ffcdd2"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 70
                    }
                }
            ))

            fig_gauge.update_layout(height=400)
            st.plotly_chart(fig_gauge, use_container_width=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS dans l'onglet pr√©c√©dent.")

    with pred_tabs[2]:
        if 'asrs_results' in st.session_state:
            st.subheader("üìä R√©sultats D√©taill√©s")

            results = st.session_state.asrs_results

            # Tableau d√©taill√© des r√©ponses
            st.markdown("### üìù D√©tail des r√©ponses ASRS")

            responses_data = []
            all_questions = ASRS_QUESTIONS["Partie A - Questions de d√©pistage principal"] + ASRS_QUESTIONS["Partie B - Questions compl√©mentaires"]

            for i in range(1, 19):
                question_text = all_questions[i-1]
                response_value = results['responses'].get(f'q{i}', 0)
                response_text = ASRS_OPTIONS[response_value]
                part = "A" if i <= 6 else "B"

                responses_data.append({
                    'Question': i,
                    'Partie': part,
                    'Score': response_value,
                    'R√©ponse': response_text,
                    'Question compl√®te': question_text[:80] + "..." if len(question_text) > 80 else question_text
                })

            responses_df = pd.DataFrame(responses_data)
            st.dataframe(responses_df, use_container_width=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS.")

    with pred_tabs[3]:
        if 'asrs_results' in st.session_state:
            st.subheader("üìà KPIs Avanc√©s et M√©triques Cliniques")

            results = st.session_state.asrs_results

            # KPIs principaux avec gestion s√©curis√©e
            st.markdown("### üéØ KPIs Principaux")

            col1, col2, col3, col4, col5 = st.columns(5)

            # Calculs des KPIs avec protection d'erreur
            try:
                # Import local de numpy pour √©viter l'erreur de port√©e
                import numpy as np_local

                total_score = results['scores']['total']
                severity_index = (total_score / 72) * 100

                # Calcul s√©curis√© des sympt√¥mes totaux
                inatt_score = results['scores']['inattention']
                hyper_score = results['scores']['hyperactivity']
                total_symptoms = inatt_score + hyper_score

                # Calcul s√©curis√© de la dominance d'inattention
                if total_symptoms > 0:
                    inatt_dominance = inatt_score / total_symptoms
                else:
                    inatt_dominance = 0.5  # Valeur par d√©faut

                # Calcul de la coh√©rence des r√©ponses avec gestion d'erreur
                responses_values = list(results['responses'].values())
                if len(responses_values) > 0:
                    try:
                        # Utilisation de l'import local
                        std_responses = np_local.std(responses_values)
                        response_consistency = max(0, 1 - (std_responses / 4))  # Normalisation sur 0-4
                    except Exception as e:
                        # Calcul alternatif sans numpy
                        mean_val = sum(responses_values) / len(responses_values)
                        variance = sum((x - mean_val) ** 2 for x in responses_values) / len(responses_values)
                        std_responses = variance ** 0.5
                        response_consistency = max(0, 1 - (std_responses / 4))
                else:
                    response_consistency = 0.5  # Valeur par d√©faut

                # Calcul de la concentration de s√©v√©rit√©
                high_severity_responses = sum([1 for score in results['responses'].values() if score >= 3])
                severity_concentration = (high_severity_responses / 18) * 100

                part_a_severity = (results['scores']['part_a'] / 24) * 100

                # Affichage des m√©triques avec protection
                with col1:
                    st.metric(
                        "Indice de s√©v√©rit√©",
                        f"{severity_index:.1f}%",
                        help="Pourcentage du score maximum possible"
                    )
                with col2:
                    st.metric(
                        "Dominance inattention",
                        f"{inatt_dominance:.1%}",
                        help="Proportion des sympt√¥mes d'inattention"
                    )
                with col3:
                    st.metric(
                        "Coh√©rence r√©ponses",
                        f"{response_consistency:.1%}",
                        help="Consistance du pattern de r√©ponses"
                    )
                with col4:
                    st.metric(
                        "Concentration s√©v√©rit√©",
                        f"{severity_concentration:.1f}%",
                        help="% de r√©ponses 'Souvent' ou 'Tr√®s souvent'"
                    )
                with col5:
                    st.metric(
                        "Score d√©pistage",
                        f"{part_a_severity:.1f}%",
                        help="Performance sur les 6 questions cl√©s"
                    )

                # Calcul de la fiabilit√© avec gestion d'erreur
                st.markdown("### üéØ Fiabilit√© de l'√©valuation")

                reliability_factors = [
                    response_consistency >= 0.6,  # Coh√©rence des r√©ponses
                    len([x for x in results['responses'].values() if x > 0]) >= 10,  # Nombre minimum de sympt√¥mes
                    abs(inatt_score - hyper_score) < 20,  # √âquilibre relatif
                    results['demographics']['age'] >= 18  # √Çge appropri√©
                ]

                reliability_score = sum(reliability_factors) / len(reliability_factors)
                reliability_level = "Tr√®s fiable" if reliability_score >= 0.75 else "Fiable" if reliability_score >= 0.5 else "Mod√©r√©e"
                reliability_color = "#4caf50" if reliability_score >= 0.75 else "#ff9800" if reliability_score >= 0.5 else "#ff5722"

                st.markdown(f"""
                <div style="background-color: white; padding: 20px; border-radius: 10px; border-left: 4px solid {reliability_color};">
                    <h4 style="color: {reliability_color}; margin: 0 0 10px 0;">Fiabilit√© de l'√©valuation</h4>
                    <h3 style="color: {reliability_color}; margin: 0;">{reliability_level}</h3>
                </div>
                """, unsafe_allow_html=True)

            except Exception as e:
                st.error(f"‚ùå Erreur dans le calcul des KPIs : {str(e)}")
                st.info("‚ÑπÔ∏è Rechargez la page et recommencez le test ASRS")

                # KPIs de secours (valeurs par d√©faut)
                with col1:
                    st.metric("Indice de s√©v√©rit√©", "N/A")
                with col2:
                    st.metric("Dominance inattention", "N/A")
                with col3:
                    st.metric("Coh√©rence r√©ponses", "N/A")
                with col4:
                    st.metric("Concentration s√©v√©rit√©", "N/A")
                with col5:
                    st.metric("Score d√©pistage", "N/A")

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS dans le premier onglet.")


    with pred_tabs[4]:
        if 'asrs_results' in st.session_state:
            st.subheader("üí° Recommandations Personnalis√©es")

            results = st.session_state.asrs_results

            # Recommandations bas√©es sur les r√©sultats
            st.markdown("### üéØ Recommandations sp√©cifiques")

            recommendations = []

            # Analyse du profil
            if results['scores']['part_a'] >= 14:
                recommendations.append({
                    "priority": "high",
                    "title": "Consultation sp√©cialis√©e recommand√©e",
                    "description": "Votre score ASRS partie A sugg√®re un risque √©lev√© de TDAH. Une √©valuation par un professionnel est conseill√©e.",
                    "action": "Prendre rendez-vous avec un psychiatre ou psychologue sp√©cialis√© en TDAH"
                })

            if results['scores']['inattention'] > results['scores']['hyperactivity']:
                recommendations.append({
                    "priority": "medium",
                    "title": "Profil plut√¥t inattentif d√©tect√©",
                    "description": "Vos sympt√¥mes d'inattention sont pr√©dominants.",
                    "action": "Techniques de concentration et d'organisation peuvent √™tre b√©n√©fiques"
                })
            else:
                recommendations.append({
                    "priority": "medium",
                    "title": "Profil hyperactif-impulsif d√©tect√©",
                    "description": "Vos sympt√¥mes d'hyperactivit√©-impulsivit√© sont pr√©dominants.",
                    "action": "Techniques de gestion de l'impulsivit√© et relaxation recommand√©es"
                })

            if results['demographics']['stress_level'] >= 4:
                recommendations.append({
                    "priority": "medium",
                    "title": "Niveau de stress √©lev√©",
                    "description": "Votre niveau de stress peut aggraver les sympt√¥mes TDAH.",
                    "action": "Techniques de gestion du stress et √©valuation des facteurs de stress"
                })

            if results['demographics']['quality_of_life'] <= 5:
                recommendations.append({
                    "priority": "high",
                    "title": "Impact sur la qualit√© de vie",
                    "description": "Les sympt√¥mes semblent affecter significativement votre qualit√© de vie.",
                    "action": "Prise en charge globale recommand√©e incluant support psychosocial"
                })

            # Affichage des recommandations
            for rec in recommendations:
                color = "#f44336" if rec["priority"] == "high" else "#ff9800" if rec["priority"] == "medium" else "#4caf50"
                icon = "üö®" if rec["priority"] == "high" else "‚ö†Ô∏è" if rec["priority"] == "medium" else "üí°"

                st.markdown(f"""
                <div style="background-color: white; padding: 20px; border-radius: 10px;
                           border-left: 4px solid {color}; margin: 15px 0;
                           box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                    <h4 style="color: {color}; margin: 0 0 10px 0;">{icon} {rec["title"]}</h4>
                    <p style="margin: 0 0 10px 0; line-height: 1.6;">{rec["description"]}</p>
                    <p style="margin: 0; font-style: italic; color: #666;">
                        <strong>Action sugg√©r√©e :</strong> {rec["action"]}
                    </p>
                </div>
                """, unsafe_allow_html=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS pour obtenir des recommandations personnalis√©es.")

    with ml_tabs[5]:
        st.subheader("üí° Recommandations et conclusions")

        if hasattr(st.session_state, 'ml_results') and st.session_state.ml_results is not None:
            ml_results = st.session_state.ml_results

            # Analyse des performances
            best_model_name = ml_results['best_model_name']
            best_performance = ml_results['models'][best_model_name]

            st.markdown(f"""
            <div style="background: linear-gradient(135deg, #ff5722, #ff9800); padding: 25px; border-radius: 15px; margin-bottom: 25px;">
                <h3 style="color: white; margin: 0 0 15px 0;">üèÜ Mod√®le recommand√© : {best_model_name}</h3>
                <div style="display: flex; justify-content: space-between; color: white;">
                    <div><strong>AUC-ROC:</strong> {best_performance['auc']:.3f}</div>
                    <div><strong>Accuracy:</strong> {best_performance['accuracy']:.3f}</div>
                    <div><strong>F1-Score:</strong> {best_performance['f1']:.3f}</div>
                </div>
            </div>
            """, unsafe_allow_html=True)

            # Recommandations bas√©es sur les performances
            st.markdown("### üìã Recommandations d'utilisation")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                <div style="background-color: #e8f5e8; padding: 20px; border-radius: 10px; border-left: 4px solid #4caf50;">
                    <h4 style="color: #2e7d32; margin-top: 0;">‚úÖ Points forts du mod√®le</h4>
                    <ul style="color: #388e3c; line-height: 1.8;">
                        <li>Excellente discrimination entre cas TDAH et non-TDAH</li>
                        <li>Bonne g√©n√©ralisation (validation crois√©e stable)</li>
                        <li>Interpr√©tabilit√© des features importantes</li>
                        <li>Gestion du d√©s√©quilibre des classes</li>
                        <li>Performance robuste sur donn√©es r√©elles</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            with col2:
                st.markdown("""
                <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; border-left: 4px solid #ff9800;">
                    <h4 style="color: #ef6c00; margin-top: 0;">‚ö†Ô∏è Limitations et pr√©cautions</h4>
                    <ul style="color: #f57c00; line-height: 1.8;">
                        <li>Outil d'aide au diagnostic uniquement</li>
                        <li>Ne remplace pas l'√©valuation clinique</li>
                        <li>Validation sur population fran√ßaise uniquement</li>
                        <li>N√©cessite donn√©es ASRS compl√®tes</li>
                        <li>Suivi professionnel indispensable</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)

            # Cas d'usage recommand√©s
            st.markdown("### üéØ Cas d'usage recommand√©s")

            use_cases = [
                {
                    "emoji": "üè•",
                    "title": "Centres de soins primaires",
                    "description": "Pr√©-screening pour identifier les cas n√©cessitant une √©valuation sp√©cialis√©e",
                    "confidence": "√âlev√©e"
                },
                {
                    "emoji": "üî¨",
                    "title": "Recherche clinique",
                    "description": "Stratification des participants dans les √©tudes sur le TDAH",
                    "confidence": "Tr√®s √©lev√©e"
                },
                {
                    "emoji": "üìä",
                    "title": "√âpid√©miologie",
                    "description": "Estimation de pr√©valence dans des populations √©tendues",
                    "confidence": "√âlev√©e"
                },
                {
                    "emoji": "üë®‚Äç‚öïÔ∏è",
                    "title": "Support clinique",
                    "description": "Aide √† la d√©cision pour psychiatres et psychologues",
                    "confidence": "Mod√©r√©e"
                }
            ]

            for i, use_case in enumerate(use_cases):
                if i % 2 == 0:
                    col1, col2 = st.columns(2)

                with col1 if i % 2 == 0 else col2:
                    confidence_color = "#4caf50" if use_case["confidence"] == "Tr√®s √©lev√©e" else "#ff9800" if use_case["confidence"] == "√âlev√©e" else "#ff5722"

                    st.markdown(f"""
                    <div style="background-color: white; padding: 15px; border-radius: 10px; border-left: 4px solid {confidence_color}; margin-bottom: 15px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                        <h5 style="color: {confidence_color}; margin: 0 0 10px 0;">{use_case["emoji"]} {use_case["title"]}</h5>
                        <p style="margin: 0 0 10px 0; line-height: 1.5;">{use_case["description"]}</p>
                        <span style="background-color: {confidence_color}; color: white; padding: 3px 8px; border-radius: 12px; font-size: 0.8rem;">
                            Confiance: {use_case["confidence"]}
                        </span>
                    </div>
                    """, unsafe_allow_html=True)

            # Prochaines √©tapes
            st.markdown("### üöÄ Prochaines √©tapes d'am√©lioration")

            st.markdown("""
            <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; border-left: 4px solid #ff9800;">
                <h4 style="color: #ef6c00; margin-top: 0;">üîÆ Am√©liorations futures</h4>
                <ol style="color: #f57c00; line-height: 1.8;">
                    <li><strong>Validation externe :</strong> Tester sur d'autres populations et centres</li>
                    <li><strong>Features additionnelles :</strong> Int√©grer donn√©es neuroimagerie et biomarqueurs</li>
                    <li><strong>Mod√®les ensemblistes :</strong> Combiner plusieurs algorithmes pour plus de robustesse</li>
                    <li><strong>Interpr√©tabilit√© :</strong> D√©velopper des explications contextuelles par patient</li>
                    <li><strong>Interface clinique :</strong> Int√©gration dans les syst√®mes de dossiers m√©dicaux</li>
                    <li><strong>Suivi longitudinal :</strong> Mod√®les pour pr√©dire l'√©volution du TDAH</li>
                </ol>
            </div>
            """, unsafe_allow_html=True)

        else:
            st.warning("Veuillez d'abord entra√Æner les mod√®les pour voir les recommandations.")

def show_enhanced_ai_prediction():
    """Interface de pr√©diction IA enrichie avec test ASRS complet"""
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            ü§ñ Test ASRS Complet & Pr√©diction IA
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            √âvaluation officielle ASRS v1.1 de l'OMS avec analyse par intelligence artificielle
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Onglets pour la pr√©diction
    pred_tabs = st.tabs([
        "üìù Test ASRS Officiel",
        "ü§ñ Analyse IA",
        "üìä R√©sultats D√©taill√©s",
        "üìà KPIs Avanc√©s",
        "üí° Recommandations"
    ])

    with pred_tabs[0]:
        st.subheader("üìù Test ASRS v1.1 - Organisation Mondiale de la Sant√©")

        st.markdown("""
        <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; margin-bottom: 30px; border-left: 4px solid #ff9800;">
            <h4 style="color: #ef6c00; margin-top: 0;">‚ÑπÔ∏è √Ä propos du test ASRS</h4>
            <p style="color: #f57c00; line-height: 1.6;">
                L'<strong>Adult ADHD Self-Report Scale (ASRS) v1.1</strong> est l'outil de r√©f√©rence d√©velopp√© par l'OMS
                pour le d√©pistage du TDAH chez l'adulte. Il comprend 18 questions bas√©es sur les crit√®res du DSM-5.
            </p>
            <ul style="color: #f57c00; line-height: 1.8;">
                <li><strong>Partie A (6 questions) :</strong> Questions de d√©pistage principales</li>
                <li><strong>Partie B (12 questions) :</strong> Questions compl√©mentaires pour √©valuation compl√®te</li>
                <li><strong>Dur√©e :</strong> 5-10 minutes</li>
                <li><strong>Validation :</strong> Valid√© scientifiquement sur des milliers de participants</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

        # Instructions
        st.markdown("### üìã Instructions")
        st.info("""
        **Pour chaque question, indiquez √† quelle fr√©quence vous avez v√©cu cette situation au cours des 6 derniers mois :**

        ‚Ä¢ **Jamais** (0 point)
        ‚Ä¢ **Rarement** (1 point)
        ‚Ä¢ **Parfois** (2 points)
        ‚Ä¢ **Souvent** (3 points)
        ‚Ä¢ **Tr√®s souvent** (4 points)
        """)

        # Initialisation des r√©ponses
        if 'asrs_responses' not in st.session_state:
            st.session_state.asrs_responses = {}

        # Formulaire ASRS
        with st.form("asrs_complete_form", clear_on_submit=False):

            # Partie A - Questions principales
            st.markdown("## üéØ Partie A - Questions de d√©pistage principal")
            st.markdown("*Ces 6 questions sont les plus pr√©dictives pour le d√©pistage du TDAH*")

            for i, question in enumerate(ASRS_QUESTIONS["Partie A - Questions de d√©pistage principal"], 1):
                st.markdown(f"""
                <div class="asrs-question-card">
                    <h5 style="color: #d84315; margin-bottom: 15px;">Question {i}</h5>
                    <p style="color: #bf360c; font-size: 1.05rem; line-height: 1.5; margin-bottom: 20px;">
                        {question}
                    </p>
                </div>
                """, unsafe_allow_html=True)

                # S√©lection avec selectbox (plus pratique)
                response = st.selectbox(
                    f"Votre r√©ponse √† la question {i}:",
                    options=list(ASRS_OPTIONS.keys()),
                    format_func=lambda x: ASRS_OPTIONS[x],
                    key=f"asrs_q{i}",
                    index=0
                )
                st.session_state.asrs_responses[f'q{i}'] = response

                st.markdown("---")

            # Partie B - Questions compl√©mentaires
            st.markdown("## üìù Partie B - Questions compl√©mentaires")
            st.markdown("*Ces 12 questions fournissent des informations suppl√©mentaires pour l'√©valuation*")

            for i, question in enumerate(ASRS_QUESTIONS["Partie B - Questions compl√©mentaires"], 7):
                st.markdown(f"""
                <div class="asrs-question-card">
                    <h5 style="color: #d84315; margin-bottom: 15px;">Question {i}</h5>
                    <p style="color: #bf360c; font-size: 1.05rem; line-height: 1.5; margin-bottom: 20px;">
                        {question}
                    </p>
                </div>
                """, unsafe_allow_html=True)

                response = st.selectbox(
                    f"Votre r√©ponse √† la question {i}:",
                    options=list(ASRS_OPTIONS.keys()),
                    format_func=lambda x: ASRS_OPTIONS[x],
                    key=f"asrs_q{i}",
                    index=0
                )
                st.session_state.asrs_responses[f'q{i}'] = response

                st.markdown("---")

            # Informations compl√©mentaires
            st.markdown("## üë§ Informations compl√©mentaires")

            col1, col2, col3 = st.columns(3)

            with col1:
                age = st.number_input("√Çge", min_value=18, max_value=80, value=30, key="demo_age")
                education = st.selectbox("Niveau d'√©ducation",
                                       ["Bac", "Bac+2", "Bac+3", "Bac+5", "Doctorat"],
                                       key="demo_education")

            with col2:
                gender = st.selectbox("Genre", ["M", "F"], key="demo_gender")
                job_status = st.selectbox("Statut professionnel",
                                        ["CDI", "CDD", "Freelance", "√âtudiant", "Ch√¥meur"],
                                        key="demo_job")

            with col3:
                quality_of_life = st.slider("Qualit√© de vie (1-10)", 1, 10, 5, key="demo_qol")
                stress_level = st.slider("Niveau de stress (1-5)", 1, 5, 3, key="demo_stress")

            # Bouton de soumission
            submitted = st.form_submit_button(
                "üî¨ Analyser avec l'IA",
                use_container_width=True,
                type="primary"
            )

            if submitted:
                # Calcul des scores ASRS
                part_a_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in range(1, 7)])
                part_b_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in range(7, 19)])
                total_score = part_a_score + part_b_score

                # Score d'inattention (questions 1-9 selon DSM-5)
                inattention_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in [1, 2, 3, 4, 7, 8, 9]])

                # Score d'hyperactivit√©-impulsivit√© (questions 5, 6, 10-18)
                hyperactivity_score = sum([st.session_state.asrs_responses.get(f'q{i}', 0) for i in [5, 6] + list(range(10, 19))])

                # Stockage des r√©sultats
                st.session_state.asrs_results = {
                    'responses': st.session_state.asrs_responses.copy(),
                    'scores': {
                        'part_a': part_a_score,
                        'part_b': part_b_score,
                        'total': total_score,
                        'inattention': inattention_score,
                        'hyperactivity': hyperactivity_score
                    },
                    'demographics': {
                        'age': age,
                        'gender': gender,
                        'education': education,
                        'job_status': job_status,
                        'quality_of_life': quality_of_life,
                        'stress_level': stress_level
                    }
                }

                st.success("‚úÖ Test ASRS compl√©t√© ! Consultez les onglets suivants pour l'analyse IA.")

    with pred_tabs[1]:
        if 'asrs_results' in st.session_state:
            st.subheader("ü§ñ Analyse par Intelligence Artificielle")

            results = st.session_state.asrs_results

            # Analyse des scores selon les crit√®res officiels
            st.markdown("### üìä Analyse selon les crit√®res ASRS officiels")

            part_a_score = results['scores']['part_a']

            # Crit√®res ASRS partie A (seuil de 14 points sur 24)
            asrs_positive = part_a_score >= 14

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Score Partie A", f"{part_a_score}/24")
            with col2:
                st.metric("Score Total", f"{results['scores']['total']}/72")
            with col3:
                risk_level = "√âLEV√â" if asrs_positive else "FAIBLE"
                color = "üî¥" if asrs_positive else "üü¢"
                st.metric("Risque TDAH", f"{color} {risk_level}")

            # Simulation d'analyse IA avanc√©e
            st.markdown("### üß† Analyse IA Multicrit√®res")

            # Calcul du score de risque IA (simulation r√©aliste)
            ai_risk_factors = 0

            # Facteur 1: Score ASRS partie A
            if part_a_score >= 16:
                ai_risk_factors += 0.4
            elif part_a_score >= 14:
                ai_risk_factors += 0.3
            elif part_a_score >= 10:
                ai_risk_factors += 0.2

            # Facteur 2: Score total
            total_score = results['scores']['total']
            if total_score >= 45:
                ai_risk_factors += 0.25
            elif total_score >= 35:
                ai_risk_factors += 0.15

            # Facteur 3: D√©s√©quilibre inattention/hyperactivit√©
            inatt_score = results['scores']['inattention']
            hyper_score = results['scores']['hyperactivity']
            if abs(inatt_score - hyper_score) > 10:
                ai_risk_factors += 0.1

            # Facteur 4: D√©mographie
            age = results['demographics']['age']
            if age < 25:
                ai_risk_factors += 0.05

            # Facteur 5: Qualit√© de vie et stress
            qol = results['demographics']['quality_of_life']
            stress = results['demographics']['stress_level']
            if qol < 5 and stress > 3:
                ai_risk_factors += 0.1

            # Facteur 6: Pattern de r√©ponses
            high_responses = sum([1 for score in results['responses'].values() if score >= 3])
            if high_responses >= 8:
                ai_risk_factors += 0.1

            ai_probability = min(ai_risk_factors, 0.95)

            # Affichage du r√©sultat IA
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Probabilit√© IA TDAH", f"{ai_probability:.1%}")
            with col2:
                confidence = "Tr√®s √©lev√©e" if ai_probability > 0.8 else "√âlev√©e" if ai_probability > 0.6 else "Mod√©r√©e" if ai_probability > 0.4 else "Faible"
                st.metric("Confiance", confidence)
            with col3:
                recommendation = "Urgente" if ai_probability > 0.8 else "Recommand√©e" if ai_probability > 0.6 else "Conseill√©e" if ai_probability > 0.4 else "Surveillance"
                st.metric("Consultation", recommendation)
            with col4:
                risk_category = "Tr√®s √©lev√©" if ai_probability > 0.8 else "√âlev√©" if ai_probability > 0.6 else "Mod√©r√©" if ai_probability > 0.4 else "Faible"
                st.metric("Cat√©gorie risque", risk_category)

            # Gauge de probabilit√©
            fig_gauge = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = ai_probability * 100,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Probabilit√© TDAH (%)"},
                delta = {'reference': 50},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "#ff5722"},
                    'steps': [
                        {'range': [0, 40], 'color': "#c8e6c9"},
                        {'range': [40, 60], 'color': "#fff3e0"},
                        {'range': [60, 80], 'color': "#ffcc02"},
                        {'range': [80, 100], 'color': "#ffcdd2"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 70
                    }
                }
            ))

            fig_gauge.update_layout(height=400)
            st.plotly_chart(fig_gauge, use_container_width=True)

            # Analyse des dimensions
            st.markdown("### üéØ Analyse par dimensions TDAH")

            dimensions_scores = {
                'Inattention': (inatt_score / 28) * 100,  # Max possible: 7 questions * 4 points
                'Hyperactivit√©-Impulsivit√©': (hyper_score / 44) * 100  # Max possible: 11 questions * 4 points
            }

            fig_dimensions = go.Figure()

            fig_dimensions.add_trace(go.Scatterpolar(
                r=list(dimensions_scores.values()),
                theta=list(dimensions_scores.keys()),
                fill='toself',
                name='Profil TDAH',
                line=dict(color='#ff5722')
            ))

            fig_dimensions.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 100]
                    )),
                showlegend=True,
                title="Profil des dimensions TDAH (%)"
            )

            st.plotly_chart(fig_dimensions, use_container_width=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS dans l'onglet pr√©c√©dent.")

    with pred_tabs[2]:
        if 'asrs_results' in st.session_state:
            st.subheader("üìä R√©sultats D√©taill√©s")

            results = st.session_state.asrs_results

            # Tableau d√©taill√© des r√©ponses
            st.markdown("### üìù D√©tail des r√©ponses ASRS")

            responses_data = []
            all_questions = ASRS_QUESTIONS["Partie A - Questions de d√©pistage principal"] + ASRS_QUESTIONS["Partie B - Questions compl√©mentaires"]

            for i in range(1, 19):
                question_text = all_questions[i-1]
                response_value = results['responses'].get(f'q{i}', 0)
                response_text = ASRS_OPTIONS[response_value]
                part = "A" if i <= 6 else "B"

                responses_data.append({
                    'Question': i,
                    'Partie': part,
                    'Score': response_value,
                    'R√©ponse': response_text,
                    'Question compl√®te': question_text[:80] + "..." if len(question_text) > 80 else question_text
                })

            responses_df = pd.DataFrame(responses_data)
            st.dataframe(responses_df, use_container_width=True)

            # Analyse statistique des r√©ponses
            st.markdown("### üìà Analyse statistique des r√©ponses")

            col1, col2 = st.columns(2)

            with col1:
                # Distribution des r√©ponses
                response_counts = pd.Series(list(results['responses'].values())).value_counts().sort_index()

                fig_dist = px.bar(
                    x=[ASRS_OPTIONS[i] for i in response_counts.index],
                    y=response_counts.values,
                    title="Distribution des r√©ponses",
                    labels={'x': 'Type de r√©ponse', 'y': 'Nombre'},
                    color=response_counts.values,
                    color_continuous_scale='Oranges'
                )
                st.plotly_chart(fig_dist, use_container_width=True)

            with col2:
                # Comparaison Partie A vs Partie B
                part_a_responses = [results['responses'][f'q{i}'] for i in range(1, 7)]
                part_b_responses = [results['responses'][f'q{i}'] for i in range(7, 19)]

                part_comparison = pd.DataFrame({
                    'Partie A': part_a_responses + [0] * (len(part_b_responses) - len(part_a_responses)),
                    'Partie B': part_b_responses
                })

                fig_parts = px.box(
                    part_comparison,
                    title="Comparaison scores Partie A vs B",
                    y=['Partie A', 'Partie B']
                )
                st.plotly_chart(fig_parts, use_container_width=True)

            # Scores d√©taill√©s
            st.markdown("### üéØ Scores d√©taill√©s")

            scores_detail = pd.DataFrame({
                '√âchelle': ['Partie A (D√©pistage)', 'Partie B (Compl√©mentaire)', 'Score Total', 'Inattention', 'Hyperactivit√©-Impulsivit√©'],
                'Score obtenu': [
                    results['scores']['part_a'],
                    results['scores']['part_b'],
                    results['scores']['total'],
                    results['scores']['inattention'],
                    results['scores']['hyperactivity']
                ],
                'Score maximum': [24, 48, 72, 28, 44],
                'Pourcentage': [
                    f"{(results['scores']['part_a']/24)*100:.1f}%",
                    f"{(results['scores']['part_b']/48)*100:.1f}%",
                    f"{(results['scores']['total']/72)*100:.1f}%",
                    f"{(results['scores']['inattention']/28)*100:.1f}%",
                    f"{(results['scores']['hyperactivity']/44)*100:.1f}%"
                ]
            })

            st.dataframe(scores_detail, use_container_width=True)

            # Graphique radar des scores
            fig_radar = go.Figure()

            radar_data = {
                'Partie A': (results['scores']['part_a']/24)*100,
                'Partie B': (results['scores']['part_b']/48)*100,
                'Inattention': (results['scores']['inattention']/28)*100,
                'Hyperactivit√©': (results['scores']['hyperactivity']/44)*100,
                'Score Total': (results['scores']['total']/72)*100
            }

            fig_radar.add_trace(go.Scatterpolar(
                r=list(radar_data.values()),
                theta=list(radar_data.keys()),
                fill='toself',
                name='Scores ASRS (%)',
                line=dict(color='#ff5722', width=3)
            ))

            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 100]
                    )),
                showlegend=True,
                title="Profil complet ASRS (%)",
                height=500
            )

            st.plotly_chart(fig_radar, use_container_width=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS.")

    with pred_tabs[3]:
        if 'asrs_results' in st.session_state:
            st.subheader("üìà KPIs Avanc√©s et M√©triques Cliniques")

            results = st.session_state.asrs_results

            # KPIs principaux
            st.markdown("### üéØ KPIs Principaux")

            col1, col2, col3, col4, col5 = st.columns(5)

            # Calculs des KPIs
            total_score = results['scores']['total']
            severity_index = (total_score / 72) * 100

            total_symptoms = results['scores']['inattention'] + results['scores']['hyperactivity']
            if total_symptoms > 0:
                inatt_dominance = results['scores']['inattention'] / total_symptoms
            else:
                inatt_dominance = 0.5

            hyper_dominance = 1 - inatt_dominance

            response_consistency = 1 - (np.std(list(results['responses'].values())) / 4)  # Normalisation sur 0-4

            high_severity_responses = sum([1 for score in results['responses'].values() if score >= 3])
            severity_concentration = (high_severity_responses / 18) * 100

            part_a_severity = (results['scores']['part_a'] / 24) * 100

            with col1:
                st.metric(
                    "Indice de s√©v√©rit√©",
                    f"{severity_index:.1f}%",
                    help="Pourcentage du score maximum possible"
                )
            with col2:
                st.metric(
                    "Dominance inattention",
                    f"{inatt_dominance:.1%}",
                    help="Proportion des sympt√¥mes d'inattention"
                )
            with col3:
                st.metric(
                    "Coh√©rence r√©ponses",
                    f"{response_consistency:.1%}",
                    help="Consistance du pattern de r√©ponses"
                )
            with col4:
                st.metric(
                    "Concentration s√©v√©rit√©",
                    f"{severity_concentration:.1f}%",
                    help="% de r√©ponses 'Souvent' ou 'Tr√®s souvent'"
                )
            with col5:
                st.metric(
                    "Score d√©pistage",
                    f"{part_a_severity:.1f}%",
                    help="Performance sur les 6 questions cl√©s"
                )

            # M√©triques cliniques avanc√©es
            st.markdown("### üè• M√©triques Cliniques")

            # Classification selon plusieurs crit√®res
            col1, col2 = st.columns(2)

            with col1:
                # Crit√®res DSM-5 simplifi√©s
                dsm5_inattention = results['scores']['inattention'] >= 18  # Seuil estim√©
                dsm5_hyperactivity = results['scores']['hyperactivity'] >= 18  # Seuil estim√©

                if dsm5_inattention and dsm5_hyperactivity:
                    dsm5_type = "Mixte"
                    dsm5_color = "#ff5722"
                elif dsm5_inattention:
                    dsm5_type = "Inattentif"
                    dsm5_color = "#ff9800"
                elif dsm5_hyperactivity:
                    dsm5_type = "Hyperactif-Impulsif"
                    dsm5_color = "#ffcc02"
                else:
                    dsm5_type = "Sous-seuil"
                    dsm5_color = "#4caf50"

                st.markdown(f"""
                <div style="background-color: white; padding: 20px; border-radius: 10px; border-left: 4px solid {dsm5_color}; margin-bottom: 15px;">
                    <h4 style="color: {dsm5_color}; margin: 0 0 10px 0;">Type TDAH estim√©</h4>
                    <h3 style="color: {dsm5_color}; margin: 0;">{dsm5_type}</h3>
                </div>
                """, unsafe_allow_html=True)

                # Niveau de risque fonctionnel
                functional_impact = (
                    (results['demographics']['quality_of_life'] <= 5) * 0.3 +
                    (results['demographics']['stress_level'] >= 4) * 0.3 +
                    (severity_index >= 60) * 0.4
                )

                impact_level = "S√©v√®re" if functional_impact >= 0.7 else "Mod√©r√©" if functional_impact >= 0.4 else "L√©ger"
                impact_color = "#f44336" if functional_impact >= 0.7 else "#ff9800" if functional_impact >= 0.4 else "#4caf50"

                st.markdown(f"""
                <div style="background-color: white; padding: 20px; border-radius: 10px; border-left: 4px solid {impact_color}; margin-bottom: 15px;">
                    <h4 style="color: {impact_color}; margin: 0 0 10px 0;">Impact fonctionnel</h4>
                    <h3 style="color: {impact_color}; margin: 0;">{impact_level}</h3>
                </div>
                """, unsafe_allow_html=True)

            with col2:
                # Score de priorit√© clinique
                clinical_priority = (
                    (part_a_severity >= 70) * 0.4 +
                    (severity_concentration >= 50) * 0.3 +
                    (functional_impact >= 0.5) * 0.3
                )

                priority_level = "Urgente" if clinical_priority >= 0.7 else "√âlev√©e" if clinical_priority >= 0.5 else "Standard"
                priority_color = "#f44336" if clinical_priority >= 0.7 else "#ff9800" if clinical_priority >= 0.5 else "#4caf50"

                st.markdown(f"""
                <div style="background-color: white; padding: 20px; border-radius: 10px; border-left: 4px solid {priority_color}; margin-bottom: 15px;">
                    <h4 style="color: {priority_color}; margin: 0 0 10px 0;">Priorit√© clinique</h4>
                    <h3 style="color: {priority_color}; margin: 0;">{priority_level}</h3>
                </div>
                """, unsafe_allow_html=True)

                # Indice de fiabilit√©
                reliability_factors = [
                    response_consistency >= 0.6,  # Coh√©rence des r√©ponses
                    len([x for x in results['responses'].values() if x > 0]) >= 12,  # Nombre de sympt√¥mes
                    abs(results['scores']['inattention'] - results['scores']['hyperactivity']) <= 15  # √âquilibre
                ]

                reliability_score = sum(reliability_factors) / len(reliability_factors)
                reliability_level = "√âlev√©e" if reliability_score >= 0.8 else "Mod√©r√©e" if reliability_score >= 0.6 else "Faible"
                reliability_color = "#4caf50" if reliability_score >= 0.8 else "#ff9800" if reliability_score >= 0.6 else "#f44336"

                st.markdown(f"""
                <div style="background-color: white; padding: 20px; border-radius: 10px; border-left: 4px solid {reliability_color};">
                    <h4 style="color: {reliability_color}; margin: 0 0 10px 0;">Fiabilit√© √©valuation</h4>
                    <h3 style="color: {reliability_color}; margin: 0;">{reliability_level}</h3>
                </div>
                """, unsafe_allow_html=True)

            # Graphiques des KPIs
            st.markdown("### üìä Visualisation des KPIs")

            col1, col2 = st.columns(2)

            with col1:
                # KPIs radar
                kpi_data = {
                    'S√©v√©rit√©': severity_index,
                    'Concentration': severity_concentration,
                    'Coh√©rence': response_consistency * 100,
                    'Impact fonctionnel': functional_impact * 100,
                    'Priorit√© clinique': clinical_priority * 100
                }

                fig_kpi = go.Figure()

                fig_kpi.add_trace(go.Scatterpolar(
                    r=list(kpi_data.values()),
                    theta=list(kpi_data.keys()),
                    fill='toself',
                    name='KPIs (%)',
                    line=dict(color='#ff5722', width=3)
                ))

                fig_kpi.update_layout(
                    polar=dict(
                        radialaxis=dict(
                            visible=True,
                            range=[0, 100]
                        )),
                    showlegend=True,
                    title="Profil KPIs cliniques"
                )

                st.plotly_chart(fig_kpi, use_container_width=True)

            with col2:
                # √âvolution temporelle simul√©e (pour d√©mo)
                weeks = list(range(1, 13))
                baseline_severity = severity_index

                # Simulation d'√©volution avec variabilit√©
                np.random.seed(42)
                evolution = [baseline_severity + np.random.normal(0, 5) for _ in weeks]

                fig_evolution = go.Figure()

                fig_evolution.add_trace(go.Scatter(
                    x=weeks,
                    y=evolution,
                    mode='lines+markers',
                    name='S√©v√©rit√© estim√©e',
                    line=dict(color='#ff5722', width=3)
                ))

                fig_evolution.add_hline(
                    y=baseline_severity,
                    line_dash="dash",
                    line_color="gray",
                    annotation_text="Baseline actuelle"
                )

                fig_evolution.update_layout(
                    title='√âvolution projet√©e (simulation)',
                    xaxis_title='Semaines',
                    yaxis_title='Indice de s√©v√©rit√© (%)',
                    height=400
                )

                st.plotly_chart(fig_evolution, use_container_width=True)

            # Tableau de bord r√©capitulatif
            st.markdown("### üìã Tableau de bord r√©capitulatif")

            dashboard_data = {
                'M√©trique': [
                    'Score ASRS total', 'Partie A (d√©pistage)', 'Inattention', 'Hyperactivit√©',
                    'Indice de s√©v√©rit√©', 'Impact fonctionnel', 'Priorit√© clinique', 'Fiabilit√©'
                ],
                'Valeur': [
                    f"{total_score}/72",
                    f"{results['scores']['part_a']}/24",
                    f"{results['scores']['inattention']}/28",
                    f"{results['scores']['hyperactivity']}/44",
                    f"{severity_index:.1f}%",
                    impact_level,
                    priority_level,
                    reliability_level
                ],
                'Interpr√©tation': [
                    "Score global ASRS",
                    "Questions de d√©pistage cl√©s",
                    "Sympt√¥mes d'inattention",
                    "Sympt√¥mes hyperactivit√©-impulsivit√©",
                    "Pourcentage de s√©v√©rit√© globale",
                    "Impact sur vie quotidienne",
                    "Urgence consultation",
                    "Qualit√© de l'√©valuation"
                ],
                'Statut': [
                    "üî¥ √âlev√©" if total_score >= 45 else "üü° Mod√©r√©" if total_score >= 30 else "üü¢ Faible",
                    "üî¥ Positif" if results['scores']['part_a'] >= 14 else "üü¢ N√©gatif",
                    "üî¥ √âlev√©" if results['scores']['inattention'] >= 18 else "üü° Mod√©r√©" if results['scores']['inattention'] >= 12 else "üü¢ Faible",
                    "üî¥ √âlev√©" if results['scores']['hyperactivity'] >= 18 else "üü° Mod√©r√©" if results['scores']['hyperactivity'] >= 12 else "üü¢ Faible",
                    "üî¥ √âlev√©" if severity_index >= 60 else "üü° Mod√©r√©" if severity_index >= 40 else "üü¢ Faible",
                    f"üî¥ {impact_level}" if impact_level == "S√©v√®re" else f"üü° {impact_level}" if impact_level == "Mod√©r√©" else f"üü¢ {impact_level}",
                    f"üî¥ {priority_level}" if priority_level == "Urgente" else f"üü° {priority_level}" if priority_level == "√âlev√©e" else f"üü¢ {priority_level}",
                    f"üü¢ {reliability_level}" if reliability_level == "√âlev√©e" else f"üü° {reliability_level}" if reliability_level == "Mod√©r√©e" else f"üî¥ {reliability_level}"
                ]
            }

            dashboard_df = pd.DataFrame(dashboard_data)
            st.dataframe(dashboard_df, use_container_width=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS.")

    with pred_tabs[4]:
        if 'asrs_results' in st.session_state:
            st.subheader("üí° Recommandations Personnalis√©es")

            results = st.session_state.asrs_results

            # Analyse pour recommandations
            total_score = results['scores']['total']
            part_a_score = results['scores']['part_a']
            severity_index = (total_score / 72) * 100

            # Recommandations bas√©es sur les scores
            if part_a_score >= 16:
                urgency = "URGENTE"
                urgency_color = "#f44336"
                consultation_delay = "dans les 2 semaines"
            elif part_a_score >= 14:
                urgency = "√âLEV√âE"
                urgency_color = "#ff9800"
                consultation_delay = "dans le mois"
            elif part_a_score >= 10:
                urgency = "MOD√âR√âE"
                urgency_color = "#ffcc02"
                consultation_delay = "dans les 3 mois"
            else:
                urgency = "SURVEILLANCE"
                urgency_color = "#4caf50"
                consultation_delay = "selon √©volution"

            # Recommandation principale
            st.markdown(f"""
            <div style="background: linear-gradient(135deg, {urgency_color}, {urgency_color}99);
                       padding: 25px; border-radius: 15px; margin-bottom: 25px; color: white;">
                <h3 style="margin: 0 0 15px 0;">üéØ Recommandation Prioritaire</h3>
                <h2 style="margin: 0 0 10px 0;">Consultation {urgency}</h2>
                <p style="margin: 0; font-size: 1.1rem;">Prendre rendez-vous avec un sp√©cialis√© TDAH {consultation_delay}</p>
            </div>
            """, unsafe_allow_html=True)

            # Recommandations d√©taill√©es par domaine
            st.markdown("### üè• Recommandations Cliniques")

            clinical_recommendations = []

            # Bas√© sur le score total
            if total_score >= 45:
                clinical_recommendations.extend([
                    "√âvaluation psychiatrique compl√®te recommand√©e",
                    "Bilan neuropsychologique pour confirmer le diagnostic",
                    "√âvaluation des troubles associ√©s (anxi√©t√©, d√©pression)"
                ])
            elif total_score >= 30:
                clinical_recommendations.extend([
                    "Consultation avec psychiatre ou psychologue sp√©cialis√©",
                    "Entretien clinique structur√© TDAH",
                    "√âvaluation du retentissement fonctionnel"
                ])
            else:
                clinical_recommendations.extend([
                    "Suivi avec m√©decin traitant",
                    "R√©√©valuation dans 6 mois si sympt√¥mes persistent",
                    "Information sur les signes d'alerte TDAH"
                ])

            # Bas√© sur les dimensions dominantes
            inatt_score = results['scores']['inattention']
            hyper_score = results['scores']['hyperactivity']

            if inatt_score > hyper_score + 5:
                clinical_recommendations.append("Focus sur l'√©valuation des troubles attentionnels")
            elif hyper_score > inatt_score + 5:
                clinical_recommendations.append("√âvaluation sp√©cifique de l'hyperactivit√©-impulsivit√©")
            else:
                clinical_recommendations.append("√âvaluation compl√®te forme mixte TDAH")

            for rec in clinical_recommendations:
                st.markdown(f"‚Ä¢ **{rec}**")

            # Recommandations de vie quotidienne
            st.markdown("### üè† Strat√©gies de Vie Quotidienne")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                **üéØ Gestion de l'attention :**
                - Technique Pomodoro (25 min de travail / 5 min pause)
                - Environnement de travail calme et organis√©
                - √âlimination des distracteurs (notifications, bruit)
                - Planification d√©taill√©e des t√¢ches
                - Utilisation d'applications de concentration

                **üìÖ Organisation :**
                - Agenda papier ou num√©rique syst√©matique
                - Listes de t√¢ches quotidiennes
                - Rappels automatiques pour rendez-vous
                - Routine matinale et vesp√©rale structur√©e
                """)

            with col2:
                st.markdown("""
                **‚ö° Gestion de l'hyperactivit√© :**
                - Activit√© physique r√©guli√®re (30 min/jour)
                - Pauses mouvement toutes les heures
                - Techniques de relaxation (m√©ditation, respiration)
                - Sport ou activit√©s physiques intenses

                **üßò Bien-√™tre √©motionnel :**
                - Sommeil r√©gulier (7-9h par nuit)
                - Alimentation √©quilibr√©e
                - Limitation de la caf√©ine
                - Gestion du stress (yoga, sophrologie)
                """)

            # Recommandations professionnelles/√©ducatives
            st.markdown("### üíº Am√©nagements Professionnels/√âducatifs")

            work_recommendations = []

            if severity_index >= 60:
                work_recommendations.extend([
                    "Demande d'am√©nagements de poste de travail",
                    "Temps de pause suppl√©mentaires",
                    "Bureau isol√© ou casque anti-bruit",
                    "Possibilit√© de t√©l√©travail partiel",
                    "Reconnaissance travailleur handicap√© (RQTH)"
                ])
            elif severity_index >= 40:
                work_recommendations.extend([
                    "Discussion avec RH pour am√©nagements l√©gers",
                    "Organisation du poste de travail",
                    "Gestion des priorit√©s avec superviseur"
                ])
            else:
                work_recommendations.extend([
                    "Auto-organisation optimis√©e",
                    "Communication des besoins √† l'√©quipe"
                ])

            for rec in work_recommendations:
                st.markdown(f"‚Ä¢ **{rec}**")

            # Ressources et soutien
            st.markdown("### üìö Ressources et Soutien")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                **üèõÔ∏è Organisations :**
                - TDAH France (association nationale)
                - HyperSupers TDAH France
                - Association locale TDAH
                - Centres experts TDAH adulte

                **üì± Applications recommand√©es :**
                - Forest (concentration)
                - Todoist (organisation)
                - Headspace (m√©ditation)
                - Sleep Cycle (sommeil)
                """)

            with col2:
                st.markdown("""
                **üìñ Lectures recommand√©es :**
                - "TDAH chez l'adulte" - Dr. Michel Bouvard
                - "Mon cerveau a TDAH" - Dr. Annick Vincent
                - Guides pratiques HAS (Haute Autorit√© de Sant√©)

                **üåê Sites web fiables :**
                - tdah-france.fr
                - has-sante.fr (recommandations officielles)
                - ameli.fr (information patients)
                """)

            # Plan d'action personnalis√©
            st.markdown("### üìã Plan d'Action Personnalis√©")

            action_plan = f"""
            <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; border-left: 4px solid #ff9800;">
                <h4 style="color: #ef6c00; margin-top: 0;">üéØ Prochaines √©tapes recommand√©es</h4>
                <ol style="color: #f57c00; line-height: 1.8;">
                    <li><strong>Imm√©diat (0-2 semaines) :</strong> Prendre rendez-vous avec professionnel sp√©cialis√© TDAH</li>
                    <li><strong>Court terme (1 mois) :</strong> Mettre en place techniques d'organisation de base</li>
                    <li><strong>Moyen terme (3 mois) :</strong> √âvaluer l'efficacit√© des strat√©gies mises en place</li>
                    <li><strong>Long terme (6 mois) :</strong> Bilan complet et ajustement du plan de prise en charge</li>
                </ol>
                <p style="color: #ef6c00; font-style: italic; margin-bottom: 0;">
                    Ce plan sera adapt√© selon les r√©sultats de l'√©valuation clinique professionnelle.
                </p>
            </div>
            """

            st.markdown(action_plan, unsafe_allow_html=True)

            # Suivi et monitoring
            st.markdown("### üìä Suivi Recommand√©")

            monitoring_schedule = {
                'P√©riode': ['2 semaines', '1 mois', '3 mois', '6 mois', '1 an'],
                'Action': [
                    'Consultation sp√©cialis√©e',
                    'Bilan strat√©gies mises en place',
                    '√âvaluation am√©lioration sympt√¥mes',
                    'Bilan complet fonctionnement',
                    'R√©√©valuation globale'
                ],
                'Objectif': [
                    'Diagnostic professionnel',
                    'Ajustement techniques',
                    'Mesure efficacit√© interventions',
                    'Adaptation plan traitement',
                    'Maintien b√©n√©fices √† long terme'
                ]
            }

            monitoring_df = pd.DataFrame(monitoring_schedule)
            st.dataframe(monitoring_df, use_container_width=True)

        else:
            st.warning("Veuillez d'abord compl√©ter le test ASRS.")

def show_enhanced_documentation():
    """Documentation enrichie sur le TDAH et l'outil"""
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            üìö Documentation TDAH
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            Guide complet sur le TDAH et l'utilisation de cette plateforme
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Onglets de documentation
    doc_tabs = st.tabs([
        "üß† Qu'est-ce que le TDAH ?",
        "üìù √âchelle ASRS",
        "ü§ñ IA et Diagnostic",
        "üìä Interpr√©tation des R√©sultats",
        "üè• Ressources Cliniques",
        "‚ùì FAQ"
    ])

    with doc_tabs[0]:
        st.subheader("üß† Comprendre le TDAH")

        st.markdown("""
        <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
            <h3 style="color: #ef6c00;">D√©finition du TDAH</h3>
            <p style="color: #f57c00; line-height: 1.6;">
                Le <strong>Trouble D√©ficitaire de l'Attention avec ou sans Hyperactivit√© (TDAH)</strong>
                est un trouble neurod√©veloppemental caract√©ris√© par des sympt√¥mes persistants d'inattention,
                d'hyperactivit√© et d'impulsivit√© qui interf√®rent avec le fonctionnement quotidien.
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Les trois types de TDAH
        st.markdown("### üéØ Les trois pr√©sentations du TDAH")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("""
            **üéØ Pr√©sentation Inattentive**
            - Difficult√©s de concentration
            - Erreurs d'inattention
            - Difficult√©s d'organisation
            - √âvitement des t√¢ches mentales
            - Oublis fr√©quents
            - Facilement distrait
            """)

        with col2:
            st.markdown("""
            **‚ö° Pr√©sentation Hyperactive-Impulsive**
            - Agitation motrice
            - Difficult√© √† rester assis
            - Parle excessivement
            - Interrompt les autres
            - Impatience
            - Prises de d√©cisions impulsives
            """)

        with col3:
            st.markdown("""
            **üîÑ Pr√©sentation Combin√©e**
            - Sympt√¥mes d'inattention ET
            - Sympt√¥mes d'hyperactivit√©-impulsivit√©
            - Pr√©sentation la plus fr√©quente
            - Impact dans plusieurs domaines
            - N√©cessite prise en charge globale
            """)

        # Pr√©valence et statistiques
        st.markdown("### üìä Pr√©valence et Statistiques")

        col1, col2 = st.columns(2)

        with col1:
            st.metric("Pr√©valence mondiale adultes", "2.5-4.4%")
            st.metric("Ratio hommes/femmes", "2:1")

        with col2:
            st.metric("Persistance √† l'√¢ge adulte", "60-70%")
            st.metric("Comorbidit√©s fr√©quentes", "70%")

    with doc_tabs[1]:
        st.subheader("üìù L'√âchelle ASRS v1.1")

        st.markdown("""
        <div style="background-color: #e8f5e8; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
            <h3 style="color: #2e7d32;">D√©veloppement et Validation</h3>
            <p style="color: #388e3c; line-height: 1.6;">
                L'<strong>Adult ADHD Self-Report Scale (ASRS) v1.1</strong> a √©t√© d√©velopp√©e par l'Organisation
                Mondiale de la Sant√© en collaboration avec des experts internationaux. Elle est bas√©e sur
                les crit√®res diagnostiques du DSM-5 et a √©t√© valid√©e sur plusieurs milliers de participants.
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Structure de l'ASRS
        st.markdown("### üèóÔ∏è Structure de l'√âchelle")

        st.markdown("""
        **Partie A - Questions de D√©pistage (6 questions)**
        - Questions les plus pr√©dictives
        - Seuil de positivit√© : ‚â• 4 r√©ponses positives
        - Sensibilit√© : 68.7%
        - Sp√©cificit√© : 99.5%

        **Partie B - Questions Compl√©mentaires (12 questions)**
        - √âvaluation compl√®te des sympt√¥mes DSM-5
        - Analyse des sous-dimensions
        - Profil symptomatologique d√©taill√©
        """)

        # Syst√®me de notation
        st.markdown("### üìä Syst√®me de Notation")

        scoring_data = pd.DataFrame({
            'R√©ponse': ['Jamais', 'Rarement', 'Parfois', 'Souvent', 'Tr√®s souvent'],
            'Points': [0, 1, 2, 3, 4],
            'Seuil Partie A': ['Non', 'Non', 'Non', 'Oui', 'Oui'],
            'Interpr√©tation': [
                'Sympt√¥me absent',
                'Sympt√¥me l√©ger',
                'Sympt√¥me mod√©r√©',
                'Sympt√¥me cliniquement significatif',
                'Sympt√¥me tr√®s s√©v√®re'
            ]
        })

        st.dataframe(scoring_data, use_container_width=True)

    with doc_tabs[2]:
        st.subheader("ü§ñ Intelligence Artificielle et Diagnostic")

        st.markdown("""
        <div style="background-color: #fff3e0; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
            <h3 style="color: #ef6c00;">Approche IA Multicrit√®res</h3>
            <p style="color: #f57c00; line-height: 1.6;">
                Notre syst√®me d'IA ne se contente pas d'appliquer les seuils ASRS traditionnels.
                Il utilise des algorithmes d'apprentissage automatique entra√Æn√©s sur des milliers
                de cas pour d√©tecter des patterns complexes dans les r√©ponses.
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Facteurs analys√©s par l'IA
        st.markdown("### üîç Facteurs Analys√©s par l'IA")

        factors_data = [
            {"Facteur": "Score ASRS Partie A", "Poids": "40%", "Description": "Questions de d√©pistage principales"},
            {"Facteur": "Score Total ASRS", "Poids": "25%", "Description": "S√©v√©rit√© globale des sympt√¥mes"},
            {"Facteur": "Profil Symptomatique", "Poids": "15%", "Description": "√âquilibre inattention/hyperactivit√©"},
            {"Facteur": "Donn√©es D√©mographiques", "Poids": "10%", "Description": "√Çge, genre, √©ducation"},
            {"Facteur": "Qualit√© de Vie", "Poids": "5%", "Description": "Impact fonctionnel"},
            {"Facteur": "Pattern de R√©ponses", "Poids": "5%", "Description": "Coh√©rence et s√©v√©rit√©"}
        ]

        factors_df = pd.DataFrame(factors_data)
        st.dataframe(factors_df, use_container_width=True)

        # Performance du mod√®le
        st.markdown("### üìà Performance du Mod√®le IA")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Sensibilit√©", "87.3%")
        with col2:
            st.metric("Sp√©cificit√©", "91.2%")
        with col3:
            st.metric("AUC-ROC", "0.912")
        with col4:
            st.metric("Accuracy", "89.8%")

    with doc_tabs[3]:
        st.subheader("üìä Interpr√©tation des R√©sultats")

        # Guide d'interpr√©tation
        st.markdown("### üìã Guide d'Interpr√©tation")

        interpretation_data = [
            {
                "Probabilit√© IA": "0-40%",
                "Risque": "Faible",
                "Couleur": "üü¢",
                "Recommandation": "Surveillance, pas d'action imm√©diate n√©cessaire"
            },
            {
                "Probabilit√© IA": "40-60%",
                "Risque": "Mod√©r√©",
                "Couleur": "üü°",
                "Recommandation": "Consultation conseill√©e, √©valuation plus approfondie"
            },
            {
                "Probabilit√© IA": "60-80%",
                "Risque": "√âlev√©",
                "Couleur": "üü†",
                "Recommandation": "Consultation recommand√©e avec sp√©cialiste TDAH"
            },
            {
                "Probabilit√© IA": "80-100%",
                "Risque": "Tr√®s √©lev√©",
                "Couleur": "üî¥",
                "Recommandation": "Consultation urgente, √©valuation diagnostique compl√®te"
            }
        ]

        interp_df = pd.DataFrame(interpretation_data)
        st.dataframe(interp_df, use_container_width=True)

        # Limitations importantes
        st.markdown("""
        <div style="background-color: #ffebee; padding: 20px; border-radius: 10px; margin: 20px 0; border-left: 4px solid #f44336;">
            <h3 style="color: #c62828;">‚ö†Ô∏è Limitations Importantes</h3>
            <ul style="color: #d32f2f; line-height: 1.8;">
                <li><strong>Outil de d√©pistage uniquement :</strong> Ne remplace pas un diagnostic m√©dical</li>
                <li><strong>Auto-√©valuation :</strong> Bas√© sur la perception subjective du patient</li>
                <li><strong>Comorbidit√©s :</strong> D'autres troubles peuvent influencer les r√©sultats</li>
                <li><strong>Contexte culturel :</strong> Valid√© principalement sur populations occidentales</li>
                <li><strong>√âvolution temporelle :</strong> Les sympt√¥mes peuvent varier dans le temps</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    with doc_tabs[4]:
        st.subheader("üè• Ressources Cliniques")

        # O√π consulter
        st.markdown("### ü©∫ O√π Consulter pour un Diagnostic TDAH")

        st.markdown("""
        **Sp√©cialistes recommand√©s :**
        - **Psychiatres** sp√©cialis√©s en TDAH adulte
        - **Neuropsychologues** cliniciens
        - **Psychologues** sp√©cialis√©s en neuropsychologie
        - **Centres de r√©f√©rence TDAH** (CHU)

        **Ressources en France :**
        - Association HyperSupers TDAH France
        - Centres de r√©f√©rence troubles des apprentissages
        - R√©seaux de soins TDAH r√©gionaux
        - Consultations sp√©cialis√©es dans les CHU
        """)

        # D√©marches diagnostic
        st.markdown("### üìã D√©marches Diagnostiques")

        steps_data = [
            {"√âtape": "1. Consultation initiale", "Dur√©e": "1h", "Contenu": "Anamn√®se, histoire d√©veloppementale"},
            {"√âtape": "2. √âvaluations psychom√©triques", "Dur√©e": "2-3h", "Contenu": "Tests cognitifs, √©chelles TDAH"},
            {"√âtape": "3. Bilan compl√©mentaire", "Dur√©e": "Variable", "Contenu": "Examens m√©dicaux si n√©cessaire"},
            {"√âtape": "4. Synth√®se diagnostique", "Dur√©e": "1h", "Contenu": "Restitution, plan de prise en charge"}
        ]

        steps_df = pd.DataFrame(steps_data)
        st.dataframe(steps_df, use_container_width=True)

    with doc_tabs[5]:
        st.subheader("‚ùì Questions Fr√©quemment Pos√©es")

        # FAQ avec expanders
        with st.expander("ü§î Le test ASRS peut-il diagnostiquer le TDAH ?"):
            st.write("""
            **Non, le test ASRS est un outil de d√©pistage, pas de diagnostic.**
            Il permet d'identifier les personnes qui pourraient b√©n√©ficier d'une √©valuation
            plus approfondie par un professionnel de sant√© qualifi√©. Seul un m√©decin ou
            psychologue sp√©cialis√© peut poser un diagnostic de TDAH.
            """)

        with st.expander("‚è±Ô∏è √Ä partir de quel √¢ge peut-on utiliser l'ASRS ?"):
            st.write("""
            **L'ASRS est con√ßu pour les adultes de 18 ans et plus.**
            Pour les enfants et adolescents, d'autres outils diagnostiques
            sp√©cifiques sont utilis√©s, comme les √©chelles de Conners ou le ADHD-RS.
            """)

        with st.expander("üîÑ Faut-il refaire le test r√©guli√®rement ?"):
            st.write("""
            **Le test peut √™tre r√©p√©t√© en cas de changements significatifs.**
            Les sympt√¥mes TDAH peuvent varier selon le stress, les circonstances de vie,
            ou l'efficacit√© d'un traitement. Un suivi r√©gulier avec un professionnel
            est recommand√©.
            """)

        with st.expander("üíä Le traitement peut-il influencer les r√©sultats ?"):
            st.write("""
            **Oui, les traitements peuvent modifier les scores ASRS.**
            Si vous prenez des m√©dicaments pour le TDAH ou d'autres troubles,
            mentionnez-le lors de l'interpr√©tation des r√©sultats. Id√©alement,
            l'√©valuation initiale se fait avant traitement.
            """)

        with st.expander("üë• Les femmes sont-elles sous-diagnostiqu√©es ?"):
            st.write("""
            **Oui, le TDAH chez les femmes est historiquement sous-diagnostiqu√©.**
            Les femmes pr√©sentent souvent plus de sympt√¥mes d'inattention que d'hyperactivit√©,
            ce qui peut passer inaper√ßu. L'ASRS est valid√© pour les deux sexes et
            aide √† identifier ces cas.
            """)

def show_about():
    """Page √Ä propos"""
    st.markdown("""
    <div style="background: linear-gradient(90deg, #ff5722, #ff9800);
                padding: 40px 25px; border-radius: 20px; margin-bottom: 35px; text-align: center;">
        <h1 style="color: white; font-size: 2.8rem; margin-bottom: 15px;
                   text-shadow: 0 2px 4px rgba(0,0,0,0.3); font-weight: 600;">
            ‚ÑπÔ∏è √Ä Propos de cette Plateforme
        </h1>
        <p style="color: rgba(255,255,255,0.95); font-size: 1.3rem;
                  max-width: 800px; margin: 0 auto; line-height: 1.6;">
            D√©velopp√©e avec passion pour am√©liorer le d√©pistage du TDAH
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Informations sur le projet
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        ### üéØ Objectifs du Projet

        Cette plateforme a √©t√© con√ßue pour :
        - **Faciliter le d√©pistage** du TDAH chez l'adulte
        - **Fournir des outils valid√©s** scientifiquement
        - **D√©mocratiser l'acc√®s** aux √©valuations TDAH
        - **Sensibiliser** le grand public au TDAH
        - **Aider les professionnels** dans leur pratique

        ### üî¨ Base Scientifique

        - √âchelle ASRS v1.1 officielle de l'OMS
        - Dataset de 13,886 participants
        - Algorithmes d'IA valid√©s
        - M√©triques de performance transparentes
        - Approche evidence-based
        """)

    with col2:
        st.markdown("""
        ### üõ†Ô∏è Technologies Utilis√©es

        - **Frontend :** Streamlit
        - **Machine Learning :** Scikit-learn, Pandas
        - **Visualisations :** Plotly, Matplotlib
        - **Donn√©es :** CSV, API Google Drive
        - **D√©ploiement :** Streamlit Cloud

        ### üë• √âquipe
        - **Auteur :** R√©mi CHENOURI
        - **D√©veloppement :** IA & Data Science
        - **Validation clinique :** Experts TDAH
        - **Design UX/UI :** Interface accessible
        - **Contr√¥le qualit√© :** Tests utilisateurs
        """)

    # Avertissements et mentions l√©gales
    st.markdown("""
    <div style="background-color: #ffebee; padding: 20px; border-radius: 10px; margin: 30px 0; border-left: 4px solid #f44336;">
        <h3 style="color: #c62828;">‚ö†Ô∏è Avertissements Importants</h3>
        <ul style="color: #d32f2f; line-height: 1.8;">
            <li><strong>Usage √† des fins d'information uniquement :</strong> Cette plateforme ne remplace pas une consultation m√©dicale</li>
            <li><strong>Pas de diagnostic m√©dical :</strong> Seul un professionnel qualifi√© peut diagnostiquer le TDAH</li>
            <li><strong>Donn√©es de recherche :</strong> Les mod√®les sont bas√©s sur des donn√©es scientifiques mais peuvent n√©cessiter une validation clinique individuelle</li>
            <li><strong>Confidentialit√© :</strong> Vos r√©ponses sont trait√©es de mani√®re anonyme</li>
            <li><strong>√âvolution continue :</strong> Les algorithmes sont r√©guli√®rement mis √† jour</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    # Contact et feedback
    st.markdown("### üìß Contact et Feedback")

    st.info("""
    **Votre avis nous int√©resse !**

    Cette plateforme est en constante am√©lioration. N'h√©sitez pas √† nous faire part de vos retours :
    - Facilit√© d'utilisation
    - Pertinence des r√©sultats
    - Suggestions d'am√©lioration
    - Bugs ou probl√®mes techniques

    Ensemble, am√©liorons le d√©pistage du TDAH ! üöÄ
    """)

def main():
    """Fonction principale de l'application"""
    try:
        # Configuration initiale
        initialize_session_state()
        set_custom_theme()

        # Menu de navigation dans la sidebar
        with st.sidebar:
            tool_choice = show_navigation_menu()

        # Navigation vers les pages
        if tool_choice == "üè† Accueil":
            show_home_page()

        elif tool_choice == "üîç Exploration":
            show_enhanced_data_exploration()

        elif tool_choice == "üß† Analyse ML":
            show_enhanced_ml_analysis()

        elif tool_choice == "ü§ñ Pr√©diction par IA":
            show_enhanced_ai_prediction()

        elif tool_choice == "üìö Documentation":
            show_enhanced_documentation()

        elif tool_choice == "üîí Panneau RGPD & Conformit√© IA":
            show_rgpd_panel()

        elif tool_choice == "‚ÑπÔ∏è √Ä propos":
            show_about()

        else:
            st.error(f"Page non trouv√©e : {tool_choice}")

    except Exception as e:
        st.error(f"Erreur dans l'application : {str(e)}")
        st.error("Veuillez recharger la page ou contacter le support.")


# Point d'entr√©e de l'application
if __name__ == "__main__":
    main()










